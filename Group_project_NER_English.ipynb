{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group_project_NER_English.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIsYTir1LdWd"
      },
      "source": [
        "# Named Entity Recognition on the CoNLL++ Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wEHlNdHL8Nv"
      },
      "source": [
        "Notebook to train a [flair](https://github.com/flairNLP/flair) model using stacked embeddings (with word and flair contextual embeddings) to perform named entity recognition (NER). The dataset used is the [CoNLL 2003](https://www.aclweb.org/anthology/W03-0419.pdf) dataset for NER (train, dev) with a manually corrected (improved/cleaned) test set from the [CrossWeigh paper](https://arxiv.org/abs/1909.01441) called [CoNLL++](https://github.com/ZihanWangKi/CrossWeigh#data). The current state-of-the-art model on this dataset is from the CrossWeigh paper (also using flair) by [Wang et al. (2019)](https://www.aclweb.org/anthology/D19-1519/) with F1-score of [94.3%](http://nlpprogress.com/english/named_entity_recognition.html). Without using pooled-embeddings, CrossWeigh and training to a max 50 instead of 150 epochs, we get a micro F1-score of 93.5%, within 0.7 of a percentage point of the SOTA.\n",
        "\n",
        "The notebook is structured as follows:\n",
        "* Setting up the GPU Environment\n",
        "* Getting Data\n",
        "* Training and Testing the Model\n",
        "* Using the Model (Running Inference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YbAAbVsOLyp"
      },
      "source": [
        "## Task Description\n",
        "\n",
        "> Named entity recognition (NER) is the task of tagging entities in text with their corresponding type. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYu2HDP_P0e5"
      },
      "source": [
        "#### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5pgQDNVB20K"
      },
      "source": [
        "%%capture\n",
        "! pip install -q flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cELWuRt3tu-Q",
        "outputId": "1e489a78-f84d-4aad-b4dc-93f50debd24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "import flair\n",
        "from typing import List\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.models import SequenceTagger\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings, TransformerWordEmbeddings\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus"
      ],
      "metadata": {
        "id": "Rz3j6dA6qTmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI558IY2P94A"
      },
      "source": [
        "# Getting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOMnhOfYP_lw"
      },
      "source": [
        "We download the data (train, test and dev sets) in the BIO format (each token in each of the sentences are tagged with Begin, Inside or Outside labels) as text files from the [CoNLL++ repository](https://github.com/ZihanWangKi/CrossWeigh) and save them to the `/content/data/` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7zEa-M6GBcv"
      },
      "source": [
        "def download_file(url, output_file):\n",
        "  Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
        "  urllib.request.urlretrieve (url, output_file)\n",
        "\n",
        "download_file('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_train.txt', '/content/data/conllpp_train.txt')\n",
        "download_file('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_dev.txt', '/content/data/conllpp_dev.txt')\n",
        "download_file('https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/master/data/conllpp_test.txt', '/content/data/conllpp_test.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0eY1HbQRAOd"
      },
      "source": [
        "Now we will use flair's built in `ColumnCorpus` object to load in our `conllpp_train.txt`, `conllpp_test.txt` and `conllpp_dev.txt` files in the `/content/data/` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iyyzMULE4JB",
        "outputId": "638d7adf-4f01-4aae-97e3-4391fe373a58"
      },
      "source": [
        "columns = {0: 'text', 3: 'ner'}\n",
        "corpus: Corpus = ColumnCorpus('/content/data/', columns,\n",
        "                              train_file='conllpp_train.txt',\n",
        "                              test_file='conllpp_test.txt',\n",
        "                              dev_file='conllpp_dev.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:35:59,930 Reading data from /content/data\n",
            "2022-06-17 08:35:59,934 Train: /content/data/conllpp_train.txt\n",
            "2022-06-17 08:35:59,937 Dev: /content/data/conllpp_dev.txt\n",
            "2022-06-17 08:35:59,939 Test: /content/data/conllpp_test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY12224EPHqu"
      },
      "source": [
        "To check that the sentences/size of the train, test and development set tally exactly with the Table 1 (train: 14987, test: 3684, dev: 3466) in the [CoNLL 2003 paper](https://www.aclweb.org/anthology/W03-0419.pdf), we will get the `len()` of the `.train`, `.test` and `.dev` sets from the `ColumnCorpus` object and print it out as a table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "2cHUGsJOIoLS",
        "outputId": "7859053e-816e-4146-9725-2c2662ac7849"
      },
      "source": [
        "import pandas as pd\n",
        "data = [[len(corpus.train), len(corpus.test), len(corpus.dev)]]\n",
        "# Prints out the dataset sizes of train test and development in a table.\n",
        "pd.DataFrame(data, columns=[\"Train\", \"Test\", \"Development\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Train  Test  Development\n",
              "0  14987  3684         3466"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44fa8567-d2af-457f-b277-86c94a84c787\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "      <th>Development</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14987</td>\n",
              "      <td>3684</td>\n",
              "      <td>3466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44fa8567-d2af-457f-b277-86c94a84c787')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44fa8567-d2af-457f-b277-86c94a84c787 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44fa8567-d2af-457f-b277-86c94a84c787');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ltHe5_vR1mw"
      },
      "source": [
        "# Training and Testing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H4kP93rR8vA"
      },
      "source": [
        "#### Train the Model\n",
        "\n",
        "To train the flair `SequenceTagger`, we use the `ModelTrainer` object with the corpus and the tagger to be trained. We use flair's sensible default options while specifying the output folder for the `SequenceTagger` model to be `/content/model/conllpp`. We also set the `embeddings_storage_mode` to be `gpu` to utilise the GPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "tag_type = 'ner'\n",
        "tag_dictionary = corpus.make_label_dictionary(label_type=tag_type)\n",
        "# For faster training and smaller models, we can comment out the flair embeddings.\n",
        "# This will significantly affect the performance though.\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "    WordEmbeddings('glove'),\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "    TransformerWordEmbeddings('bert-base-uncased')\n",
        "]\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=False)\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "7iVHJLM2qJ1x",
        "outputId": "b35358af-c246-4064-903f-35e4fc8d4710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:36:07,292 Computing label dictionary. Progress:\n",
            "2022-06-17 08:36:07,757 Dictionary created for label 'ner' with 5 values: LOC (seen 7140 times), PER (seen 6600 times), ORG (seen 6321 times), MISC (seen 3438 times)\n",
            "2022-06-17 08:36:08,264 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmph49_am7f\n",
            "2022-06-17 08:36:15,836 copying /tmp/tmph49_am7f to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n",
            "2022-06-17 08:36:16,038 removing temp file /tmp/tmph49_am7f\n",
            "2022-06-17 08:36:16,401 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpjg2stgyr\n",
            "2022-06-17 08:36:18,503 copying /tmp/tmpjg2stgyr to cache at /root/.flair/embeddings/glove.gensim\n",
            "2022-06-17 08:36:18,533 removing temp file /tmp/tmpjg2stgyr\n",
            "2022-06-17 08:36:20,731 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmph2t88220\n",
            "2022-06-17 08:36:25,046 copying /tmp/tmph2t88220 to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n",
            "2022-06-17 08:36:25,138 removing temp file /tmp/tmph2t88220\n",
            "2022-06-17 08:36:42,904 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpucwhct8s\n",
            "2022-06-17 08:36:46,790 copying /tmp/tmpucwhct8s to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n",
            "2022-06-17 08:36:46,883 removing temp file /tmp/tmpucwhct8s\n",
            "2022-06-17 08:37:01,219 SequenceTagger predicts: Dictionary with 17 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train('/content/model/conllpp',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=50,\n",
        "              embeddings_storage_mode='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THUBIpFHmxfQ",
        "outputId": "84986c01-1074-4a83-f3f5-4340ea965a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:37:01,559 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:37:01,562 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_3): TransformerWordEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4964, out_features=4964, bias=True)\n",
            "  (rnn): LSTM(4964, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=17, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2022-06-17 08:37:01,564 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:37:01,566 Corpus: \"Corpus: 14987 train + 3466 dev + 3684 test sentences\"\n",
            "2022-06-17 08:37:01,567 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:37:01,569 Parameters:\n",
            "2022-06-17 08:37:01,572  - learning_rate: \"0.100000\"\n",
            "2022-06-17 08:37:01,574  - mini_batch_size: \"32\"\n",
            "2022-06-17 08:37:01,576  - patience: \"3\"\n",
            "2022-06-17 08:37:01,577  - anneal_factor: \"0.5\"\n",
            "2022-06-17 08:37:01,579  - max_epochs: \"50\"\n",
            "2022-06-17 08:37:01,581  - shuffle: \"True\"\n",
            "2022-06-17 08:37:01,582  - train_with_dev: \"False\"\n",
            "2022-06-17 08:37:01,584  - batch_growth_annealing: \"False\"\n",
            "2022-06-17 08:37:01,586 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:37:01,588 Model training base path: \"/content/model/conllpp\"\n",
            "2022-06-17 08:37:01,589 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:37:01,592 Device: cuda:0\n",
            "2022-06-17 08:37:01,593 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:37:01,597 Embeddings storage mode: cpu\n",
            "2022-06-17 08:37:01,599 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:37:24,154 epoch 1 - iter 46/469 - loss 0.82582997 - samples/sec: 65.29 - lr: 0.100000\n",
            "2022-06-17 08:37:46,695 epoch 1 - iter 92/469 - loss 0.61240277 - samples/sec: 65.32 - lr: 0.100000\n",
            "2022-06-17 08:38:06,646 epoch 1 - iter 138/469 - loss 0.52536342 - samples/sec: 73.81 - lr: 0.100000\n",
            "2022-06-17 08:38:24,614 epoch 1 - iter 184/469 - loss 0.46896029 - samples/sec: 81.96 - lr: 0.100000\n",
            "2022-06-17 08:38:43,765 epoch 1 - iter 230/469 - loss 0.42066397 - samples/sec: 76.89 - lr: 0.100000\n",
            "2022-06-17 08:39:07,849 epoch 1 - iter 276/469 - loss 0.37607138 - samples/sec: 61.14 - lr: 0.100000\n",
            "2022-06-17 08:39:31,745 epoch 1 - iter 322/469 - loss 0.34506577 - samples/sec: 61.62 - lr: 0.100000\n",
            "2022-06-17 08:39:53,446 epoch 1 - iter 368/469 - loss 0.32733790 - samples/sec: 67.86 - lr: 0.100000\n",
            "2022-06-17 08:40:19,412 epoch 1 - iter 414/469 - loss 0.30404089 - samples/sec: 56.71 - lr: 0.100000\n",
            "2022-06-17 08:40:46,516 epoch 1 - iter 460/469 - loss 0.28396461 - samples/sec: 54.33 - lr: 0.100000\n",
            "2022-06-17 08:40:50,341 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:40:50,344 EPOCH 1 done: loss 0.2825 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:37<00:00,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:41:27,724 Evaluating as a multi-label problem: False\n",
            "2022-06-17 08:41:27,782 DEV : loss 0.11812306940555573 - f1-score (micro avg)  0.869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:41:28,261 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 08:41:28,266 saving best model\n",
            "2022-06-17 08:41:30,583 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:41:50,262 epoch 2 - iter 46/469 - loss 0.10664816 - samples/sec: 74.84 - lr: 0.100000\n",
            "2022-06-17 08:42:09,272 epoch 2 - iter 92/469 - loss 0.10926090 - samples/sec: 77.47 - lr: 0.100000\n",
            "2022-06-17 08:42:27,729 epoch 2 - iter 138/469 - loss 0.10664468 - samples/sec: 79.79 - lr: 0.100000\n",
            "2022-06-17 08:42:46,584 epoch 2 - iter 184/469 - loss 0.10548982 - samples/sec: 78.10 - lr: 0.100000\n",
            "2022-06-17 08:43:05,659 epoch 2 - iter 230/469 - loss 0.10270659 - samples/sec: 77.20 - lr: 0.100000\n",
            "2022-06-17 08:43:23,786 epoch 2 - iter 276/469 - loss 0.10215463 - samples/sec: 81.24 - lr: 0.100000\n",
            "2022-06-17 08:43:42,378 epoch 2 - iter 322/469 - loss 0.10103467 - samples/sec: 79.21 - lr: 0.100000\n",
            "2022-06-17 08:44:00,867 epoch 2 - iter 368/469 - loss 0.09971832 - samples/sec: 79.65 - lr: 0.100000\n",
            "2022-06-17 08:44:19,706 epoch 2 - iter 414/469 - loss 0.09844504 - samples/sec: 78.17 - lr: 0.100000\n",
            "2022-06-17 08:44:38,423 epoch 2 - iter 460/469 - loss 0.09701622 - samples/sec: 78.68 - lr: 0.100000\n",
            "2022-06-17 08:44:41,782 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:44:41,785 EPOCH 2 done: loss 0.0973 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:45:05,929 Evaluating as a multi-label problem: False\n",
            "2022-06-17 08:45:05,985 DEV : loss 0.06859636306762695 - f1-score (micro avg)  0.9084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:45:06,447 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 08:45:06,450 saving best model\n",
            "2022-06-17 08:45:11,274 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:45:30,300 epoch 3 - iter 46/469 - loss 0.07300414 - samples/sec: 77.41 - lr: 0.100000\n",
            "2022-06-17 08:45:49,349 epoch 3 - iter 92/469 - loss 0.07042413 - samples/sec: 77.31 - lr: 0.100000\n",
            "2022-06-17 08:46:08,529 epoch 3 - iter 138/469 - loss 0.06810115 - samples/sec: 76.78 - lr: 0.100000\n",
            "2022-06-17 08:46:27,168 epoch 3 - iter 184/469 - loss 0.06812441 - samples/sec: 79.01 - lr: 0.100000\n",
            "2022-06-17 08:46:45,829 epoch 3 - iter 230/469 - loss 0.06775666 - samples/sec: 78.92 - lr: 0.100000\n",
            "2022-06-17 08:47:04,604 epoch 3 - iter 276/469 - loss 0.06776062 - samples/sec: 78.44 - lr: 0.100000\n",
            "2022-06-17 08:47:23,271 epoch 3 - iter 322/469 - loss 0.06754492 - samples/sec: 78.89 - lr: 0.100000\n",
            "2022-06-17 08:47:42,429 epoch 3 - iter 368/469 - loss 0.06664416 - samples/sec: 76.87 - lr: 0.100000\n",
            "2022-06-17 08:48:01,301 epoch 3 - iter 414/469 - loss 0.06732273 - samples/sec: 78.03 - lr: 0.100000\n",
            "2022-06-17 08:48:20,315 epoch 3 - iter 460/469 - loss 0.06708375 - samples/sec: 77.45 - lr: 0.100000\n",
            "2022-06-17 08:48:23,597 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:48:23,599 EPOCH 3 done: loss 0.0671 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:48:46,628 Evaluating as a multi-label problem: False\n",
            "2022-06-17 08:48:46,685 DEV : loss 0.06514368206262589 - f1-score (micro avg)  0.9113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:48:47,150 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 08:48:47,153 saving best model\n",
            "2022-06-17 08:48:49,518 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:49:09,539 epoch 4 - iter 46/469 - loss 0.04963556 - samples/sec: 73.57 - lr: 0.100000\n",
            "2022-06-17 08:49:28,148 epoch 4 - iter 92/469 - loss 0.05181883 - samples/sec: 79.14 - lr: 0.100000\n",
            "2022-06-17 08:49:46,609 epoch 4 - iter 138/469 - loss 0.05256712 - samples/sec: 79.77 - lr: 0.100000\n",
            "2022-06-17 08:50:05,473 epoch 4 - iter 184/469 - loss 0.05106974 - samples/sec: 78.07 - lr: 0.100000\n",
            "2022-06-17 08:50:24,145 epoch 4 - iter 230/469 - loss 0.05212517 - samples/sec: 78.87 - lr: 0.100000\n",
            "2022-06-17 08:50:42,501 epoch 4 - iter 276/469 - loss 0.05342622 - samples/sec: 80.23 - lr: 0.100000\n",
            "2022-06-17 08:51:01,066 epoch 4 - iter 322/469 - loss 0.05303293 - samples/sec: 79.32 - lr: 0.100000\n",
            "2022-06-17 08:51:19,996 epoch 4 - iter 368/469 - loss 0.05309407 - samples/sec: 77.80 - lr: 0.100000\n",
            "2022-06-17 08:51:38,540 epoch 4 - iter 414/469 - loss 0.05386115 - samples/sec: 79.41 - lr: 0.100000\n",
            "2022-06-17 08:51:58,506 epoch 4 - iter 460/469 - loss 0.05368561 - samples/sec: 73.76 - lr: 0.100000\n",
            "2022-06-17 08:52:02,000 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:52:02,003 EPOCH 4 done: loss 0.0533 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:52:25,224 Evaluating as a multi-label problem: False\n",
            "2022-06-17 08:52:25,280 DEV : loss 0.05592651292681694 - f1-score (micro avg)  0.9319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:52:25,752 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 08:52:25,756 saving best model\n",
            "2022-06-17 08:52:28,187 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:52:47,047 epoch 5 - iter 46/469 - loss 0.03707945 - samples/sec: 78.10 - lr: 0.100000\n",
            "2022-06-17 08:53:05,539 epoch 5 - iter 92/469 - loss 0.03931884 - samples/sec: 79.63 - lr: 0.100000\n",
            "2022-06-17 08:53:23,871 epoch 5 - iter 138/469 - loss 0.03955919 - samples/sec: 80.33 - lr: 0.100000\n",
            "2022-06-17 08:53:43,356 epoch 5 - iter 184/469 - loss 0.04031406 - samples/sec: 75.58 - lr: 0.100000\n",
            "2022-06-17 08:54:01,914 epoch 5 - iter 230/469 - loss 0.04134491 - samples/sec: 79.36 - lr: 0.100000\n",
            "2022-06-17 08:54:20,947 epoch 5 - iter 276/469 - loss 0.04115907 - samples/sec: 77.37 - lr: 0.100000\n",
            "2022-06-17 08:54:39,476 epoch 5 - iter 322/469 - loss 0.04094931 - samples/sec: 79.48 - lr: 0.100000\n",
            "2022-06-17 08:54:58,196 epoch 5 - iter 368/469 - loss 0.04178397 - samples/sec: 78.67 - lr: 0.100000\n",
            "2022-06-17 08:55:16,875 epoch 5 - iter 414/469 - loss 0.04256583 - samples/sec: 78.84 - lr: 0.100000\n",
            "2022-06-17 08:55:35,795 epoch 5 - iter 460/469 - loss 0.04297785 - samples/sec: 77.84 - lr: 0.100000\n",
            "2022-06-17 08:55:39,229 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:55:39,231 EPOCH 5 done: loss 0.0429 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:56:03,318 Evaluating as a multi-label problem: False\n",
            "2022-06-17 08:56:03,374 DEV : loss 0.06525728851556778 - f1-score (micro avg)  0.9308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:56:03,832 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 08:56:03,835 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:56:22,679 epoch 6 - iter 46/469 - loss 0.03249033 - samples/sec: 78.16 - lr: 0.100000\n",
            "2022-06-17 08:56:41,760 epoch 6 - iter 92/469 - loss 0.03513061 - samples/sec: 77.17 - lr: 0.100000\n",
            "2022-06-17 08:57:00,125 epoch 6 - iter 138/469 - loss 0.03414178 - samples/sec: 80.19 - lr: 0.100000\n",
            "2022-06-17 08:57:19,138 epoch 6 - iter 184/469 - loss 0.03391527 - samples/sec: 77.45 - lr: 0.100000\n",
            "2022-06-17 08:57:37,757 epoch 6 - iter 230/469 - loss 0.03424105 - samples/sec: 79.09 - lr: 0.100000\n",
            "2022-06-17 08:57:56,383 epoch 6 - iter 276/469 - loss 0.03391994 - samples/sec: 79.06 - lr: 0.100000\n",
            "2022-06-17 08:58:15,299 epoch 6 - iter 322/469 - loss 0.03379821 - samples/sec: 77.86 - lr: 0.100000\n",
            "2022-06-17 08:58:34,168 epoch 6 - iter 368/469 - loss 0.03410488 - samples/sec: 78.04 - lr: 0.100000\n",
            "2022-06-17 08:58:52,792 epoch 6 - iter 414/469 - loss 0.03464011 - samples/sec: 79.07 - lr: 0.100000\n",
            "2022-06-17 08:59:11,562 epoch 6 - iter 460/469 - loss 0.03525781 - samples/sec: 78.46 - lr: 0.100000\n",
            "2022-06-17 08:59:15,037 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 08:59:15,040 EPOCH 6 done: loss 0.0354 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:59:39,232 Evaluating as a multi-label problem: False\n",
            "2022-06-17 08:59:39,288 DEV : loss 0.0605003647506237 - f1-score (micro avg)  0.9372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:59:39,748 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 08:59:39,751 saving best model\n",
            "2022-06-17 08:59:42,106 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:00:00,531 epoch 7 - iter 46/469 - loss 0.03033401 - samples/sec: 79.94 - lr: 0.100000\n",
            "2022-06-17 09:00:19,429 epoch 7 - iter 92/469 - loss 0.02881629 - samples/sec: 77.92 - lr: 0.100000\n",
            "2022-06-17 09:00:37,882 epoch 7 - iter 138/469 - loss 0.02932266 - samples/sec: 79.81 - lr: 0.100000\n",
            "2022-06-17 09:00:56,495 epoch 7 - iter 184/469 - loss 0.02899417 - samples/sec: 79.12 - lr: 0.100000\n",
            "2022-06-17 09:01:15,495 epoch 7 - iter 230/469 - loss 0.02946683 - samples/sec: 77.51 - lr: 0.100000\n",
            "2022-06-17 09:01:34,116 epoch 7 - iter 276/469 - loss 0.02983860 - samples/sec: 79.08 - lr: 0.100000\n",
            "2022-06-17 09:01:53,554 epoch 7 - iter 322/469 - loss 0.02988618 - samples/sec: 75.76 - lr: 0.100000\n",
            "2022-06-17 09:02:12,037 epoch 7 - iter 368/469 - loss 0.02970884 - samples/sec: 79.68 - lr: 0.100000\n",
            "2022-06-17 09:02:31,040 epoch 7 - iter 414/469 - loss 0.02992546 - samples/sec: 77.49 - lr: 0.100000\n",
            "2022-06-17 09:02:50,111 epoch 7 - iter 460/469 - loss 0.03020324 - samples/sec: 77.22 - lr: 0.100000\n",
            "2022-06-17 09:02:53,564 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:02:53,567 EPOCH 7 done: loss 0.0300 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:03:17,753 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:03:17,809 DEV : loss 0.07066928595304489 - f1-score (micro avg)  0.9316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:03:18,265 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 09:03:18,270 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:03:37,434 epoch 8 - iter 46/469 - loss 0.02234818 - samples/sec: 76.85 - lr: 0.100000\n",
            "2022-06-17 09:03:56,135 epoch 8 - iter 92/469 - loss 0.02449485 - samples/sec: 78.75 - lr: 0.100000\n",
            "2022-06-17 09:04:15,421 epoch 8 - iter 138/469 - loss 0.02351552 - samples/sec: 76.36 - lr: 0.100000\n",
            "2022-06-17 09:04:33,818 epoch 8 - iter 184/469 - loss 0.02444400 - samples/sec: 80.05 - lr: 0.100000\n",
            "2022-06-17 09:04:52,550 epoch 8 - iter 230/469 - loss 0.02588167 - samples/sec: 78.62 - lr: 0.100000\n",
            "2022-06-17 09:05:11,341 epoch 8 - iter 276/469 - loss 0.02677077 - samples/sec: 78.37 - lr: 0.100000\n",
            "2022-06-17 09:05:30,180 epoch 8 - iter 322/469 - loss 0.02643766 - samples/sec: 78.17 - lr: 0.100000\n",
            "2022-06-17 09:05:49,223 epoch 8 - iter 368/469 - loss 0.02672597 - samples/sec: 77.34 - lr: 0.100000\n",
            "2022-06-17 09:06:07,568 epoch 8 - iter 414/469 - loss 0.02650304 - samples/sec: 80.27 - lr: 0.100000\n",
            "2022-06-17 09:06:26,172 epoch 8 - iter 460/469 - loss 0.02668816 - samples/sec: 79.15 - lr: 0.100000\n",
            "2022-06-17 09:06:29,576 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:06:29,578 EPOCH 8 done: loss 0.0268 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:06:52,507 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:06:52,564 DEV : loss 0.061316538602113724 - f1-score (micro avg)  0.941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:06:53,023 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 09:06:53,027 saving best model\n",
            "2022-06-17 09:06:55,383 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:07:14,191 epoch 9 - iter 46/469 - loss 0.02318443 - samples/sec: 78.31 - lr: 0.100000\n",
            "2022-06-17 09:07:32,549 epoch 9 - iter 92/469 - loss 0.02224040 - samples/sec: 80.22 - lr: 0.100000\n",
            "2022-06-17 09:07:51,504 epoch 9 - iter 138/469 - loss 0.02277201 - samples/sec: 77.69 - lr: 0.100000\n",
            "2022-06-17 09:08:10,444 epoch 9 - iter 184/469 - loss 0.02286215 - samples/sec: 77.76 - lr: 0.100000\n",
            "2022-06-17 09:08:29,230 epoch 9 - iter 230/469 - loss 0.02249184 - samples/sec: 78.39 - lr: 0.100000\n",
            "2022-06-17 09:08:48,049 epoch 9 - iter 276/469 - loss 0.02228962 - samples/sec: 78.25 - lr: 0.100000\n",
            "2022-06-17 09:09:06,881 epoch 9 - iter 322/469 - loss 0.02266756 - samples/sec: 78.20 - lr: 0.100000\n",
            "2022-06-17 09:09:27,069 epoch 9 - iter 368/469 - loss 0.02292603 - samples/sec: 72.94 - lr: 0.100000\n",
            "2022-06-17 09:09:45,763 epoch 9 - iter 414/469 - loss 0.02368841 - samples/sec: 78.78 - lr: 0.100000\n",
            "2022-06-17 09:10:04,855 epoch 9 - iter 460/469 - loss 0.02450544 - samples/sec: 77.13 - lr: 0.100000\n",
            "2022-06-17 09:10:08,260 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:10:08,263 EPOCH 9 done: loss 0.0245 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:10:31,168 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:10:31,226 DEV : loss 0.06465733796358109 - f1-score (micro avg)  0.9429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:10:31,687 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 09:10:31,690 saving best model\n",
            "2022-06-17 09:10:34,126 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:10:53,632 epoch 10 - iter 46/469 - loss 0.02001901 - samples/sec: 75.51 - lr: 0.100000\n",
            "2022-06-17 09:11:12,518 epoch 10 - iter 92/469 - loss 0.02294139 - samples/sec: 77.98 - lr: 0.100000\n",
            "2022-06-17 09:11:30,788 epoch 10 - iter 138/469 - loss 0.02276614 - samples/sec: 80.61 - lr: 0.100000\n",
            "2022-06-17 09:11:50,019 epoch 10 - iter 184/469 - loss 0.02411678 - samples/sec: 76.57 - lr: 0.100000\n",
            "2022-06-17 09:12:09,115 epoch 10 - iter 230/469 - loss 0.02394284 - samples/sec: 77.11 - lr: 0.100000\n",
            "2022-06-17 09:12:28,074 epoch 10 - iter 276/469 - loss 0.02367305 - samples/sec: 77.68 - lr: 0.100000\n",
            "2022-06-17 09:12:46,888 epoch 10 - iter 322/469 - loss 0.02323622 - samples/sec: 78.27 - lr: 0.100000\n",
            "2022-06-17 09:13:05,471 epoch 10 - iter 368/469 - loss 0.02403946 - samples/sec: 79.25 - lr: 0.100000\n",
            "2022-06-17 09:13:24,358 epoch 10 - iter 414/469 - loss 0.02381862 - samples/sec: 77.97 - lr: 0.100000\n",
            "2022-06-17 09:13:42,787 epoch 10 - iter 460/469 - loss 0.02382482 - samples/sec: 79.91 - lr: 0.100000\n",
            "2022-06-17 09:13:46,059 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:13:46,061 EPOCH 10 done: loss 0.0238 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:14:10,347 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:14:10,408 DEV : loss 0.08457881957292557 - f1-score (micro avg)  0.9229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:14:10,875 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 09:14:10,878 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:14:29,165 epoch 11 - iter 46/469 - loss 0.01367001 - samples/sec: 80.54 - lr: 0.100000\n",
            "2022-06-17 09:14:48,100 epoch 11 - iter 92/469 - loss 0.01827306 - samples/sec: 77.77 - lr: 0.100000\n",
            "2022-06-17 09:15:07,276 epoch 11 - iter 138/469 - loss 0.01995286 - samples/sec: 76.80 - lr: 0.100000\n",
            "2022-06-17 09:15:25,730 epoch 11 - iter 184/469 - loss 0.01955979 - samples/sec: 79.80 - lr: 0.100000\n",
            "2022-06-17 09:15:44,785 epoch 11 - iter 230/469 - loss 0.01931854 - samples/sec: 77.29 - lr: 0.100000\n",
            "2022-06-17 09:16:03,583 epoch 11 - iter 276/469 - loss 0.02008795 - samples/sec: 78.34 - lr: 0.100000\n",
            "2022-06-17 09:16:22,516 epoch 11 - iter 322/469 - loss 0.02073722 - samples/sec: 77.78 - lr: 0.100000\n",
            "2022-06-17 09:16:41,316 epoch 11 - iter 368/469 - loss 0.02086946 - samples/sec: 78.33 - lr: 0.100000\n",
            "2022-06-17 09:17:00,466 epoch 11 - iter 414/469 - loss 0.02084017 - samples/sec: 76.90 - lr: 0.100000\n",
            "2022-06-17 09:17:19,085 epoch 11 - iter 460/469 - loss 0.02115362 - samples/sec: 79.10 - lr: 0.100000\n",
            "2022-06-17 09:17:22,630 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:17:22,632 EPOCH 11 done: loss 0.0214 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:17:46,865 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:17:46,923 DEV : loss 0.06976239383220673 - f1-score (micro avg)  0.9343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:17:47,391 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 09:17:47,394 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:18:06,607 epoch 12 - iter 46/469 - loss 0.02116102 - samples/sec: 76.66 - lr: 0.100000\n",
            "2022-06-17 09:18:25,440 epoch 12 - iter 92/469 - loss 0.02004949 - samples/sec: 78.19 - lr: 0.100000\n",
            "2022-06-17 09:18:44,340 epoch 12 - iter 138/469 - loss 0.01898506 - samples/sec: 77.92 - lr: 0.100000\n",
            "2022-06-17 09:19:03,156 epoch 12 - iter 184/469 - loss 0.01985672 - samples/sec: 78.27 - lr: 0.100000\n",
            "2022-06-17 09:19:21,992 epoch 12 - iter 230/469 - loss 0.02006663 - samples/sec: 78.18 - lr: 0.100000\n",
            "2022-06-17 09:19:40,711 epoch 12 - iter 276/469 - loss 0.02021258 - samples/sec: 78.67 - lr: 0.100000\n",
            "2022-06-17 09:19:59,594 epoch 12 - iter 322/469 - loss 0.02038927 - samples/sec: 77.98 - lr: 0.100000\n",
            "2022-06-17 09:20:18,218 epoch 12 - iter 368/469 - loss 0.02015223 - samples/sec: 79.07 - lr: 0.100000\n",
            "2022-06-17 09:20:36,832 epoch 12 - iter 414/469 - loss 0.02022027 - samples/sec: 79.12 - lr: 0.100000\n",
            "2022-06-17 09:20:55,675 epoch 12 - iter 460/469 - loss 0.02023199 - samples/sec: 78.15 - lr: 0.100000\n",
            "2022-06-17 09:20:59,174 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:20:59,176 EPOCH 12 done: loss 0.0202 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:21:22,125 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:21:22,183 DEV : loss 0.09573764353990555 - f1-score (micro avg)  0.9266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:21:22,647 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 09:21:22,650 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:21:43,117 epoch 13 - iter 46/469 - loss 0.01731218 - samples/sec: 71.96 - lr: 0.100000\n",
            "2022-06-17 09:22:01,455 epoch 13 - iter 92/469 - loss 0.01682571 - samples/sec: 80.31 - lr: 0.100000\n",
            "2022-06-17 09:22:20,344 epoch 13 - iter 138/469 - loss 0.01752675 - samples/sec: 77.96 - lr: 0.100000\n",
            "2022-06-17 09:22:39,388 epoch 13 - iter 184/469 - loss 0.01859821 - samples/sec: 77.33 - lr: 0.100000\n",
            "2022-06-17 09:22:58,229 epoch 13 - iter 230/469 - loss 0.01878501 - samples/sec: 78.16 - lr: 0.100000\n",
            "2022-06-17 09:23:16,992 epoch 13 - iter 276/469 - loss 0.01900426 - samples/sec: 78.49 - lr: 0.100000\n",
            "2022-06-17 09:23:36,212 epoch 13 - iter 322/469 - loss 0.01849791 - samples/sec: 76.62 - lr: 0.100000\n",
            "2022-06-17 09:23:54,442 epoch 13 - iter 368/469 - loss 0.01890696 - samples/sec: 80.78 - lr: 0.100000\n",
            "2022-06-17 09:24:13,966 epoch 13 - iter 414/469 - loss 0.01930796 - samples/sec: 75.42 - lr: 0.100000\n",
            "2022-06-17 09:24:32,917 epoch 13 - iter 460/469 - loss 0.01915958 - samples/sec: 77.70 - lr: 0.100000\n",
            "2022-06-17 09:24:36,166 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:24:36,169 EPOCH 13 done: loss 0.0191 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:24:59,203 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:24:59,261 DEV : loss 0.08056985586881638 - f1-score (micro avg)  0.9349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:24:59,733 Epoch    13: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-06-17 09:24:59,735 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 09:24:59,739 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:25:19,048 epoch 14 - iter 46/469 - loss 0.01198959 - samples/sec: 76.28 - lr: 0.050000\n",
            "2022-06-17 09:25:38,199 epoch 14 - iter 92/469 - loss 0.01222317 - samples/sec: 76.90 - lr: 0.050000\n",
            "2022-06-17 09:25:56,724 epoch 14 - iter 138/469 - loss 0.01088085 - samples/sec: 79.49 - lr: 0.050000\n",
            "2022-06-17 09:26:15,498 epoch 14 - iter 184/469 - loss 0.01112383 - samples/sec: 78.43 - lr: 0.050000\n",
            "2022-06-17 09:26:34,758 epoch 14 - iter 230/469 - loss 0.01061163 - samples/sec: 76.46 - lr: 0.050000\n",
            "2022-06-17 09:26:53,121 epoch 14 - iter 276/469 - loss 0.01046791 - samples/sec: 80.20 - lr: 0.050000\n",
            "2022-06-17 09:27:11,811 epoch 14 - iter 322/469 - loss 0.01025999 - samples/sec: 78.79 - lr: 0.050000\n",
            "2022-06-17 09:27:30,986 epoch 14 - iter 368/469 - loss 0.01039256 - samples/sec: 76.80 - lr: 0.050000\n",
            "2022-06-17 09:27:48,996 epoch 14 - iter 414/469 - loss 0.01052808 - samples/sec: 81.77 - lr: 0.050000\n",
            "2022-06-17 09:28:07,685 epoch 14 - iter 460/469 - loss 0.01016327 - samples/sec: 78.80 - lr: 0.050000\n",
            "2022-06-17 09:28:11,143 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:28:11,145 EPOCH 14 done: loss 0.0102 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:28:35,458 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:28:35,514 DEV : loss 0.10226253420114517 - f1-score (micro avg)  0.9362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:28:35,976 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 09:28:35,979 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:28:54,811 epoch 15 - iter 46/469 - loss 0.01082229 - samples/sec: 78.22 - lr: 0.050000\n",
            "2022-06-17 09:29:13,440 epoch 15 - iter 92/469 - loss 0.00879296 - samples/sec: 79.05 - lr: 0.050000\n",
            "2022-06-17 09:29:32,527 epoch 15 - iter 138/469 - loss 0.00929105 - samples/sec: 77.15 - lr: 0.050000\n",
            "2022-06-17 09:29:51,210 epoch 15 - iter 184/469 - loss 0.00854478 - samples/sec: 78.82 - lr: 0.050000\n",
            "2022-06-17 09:30:09,765 epoch 15 - iter 230/469 - loss 0.00828697 - samples/sec: 79.37 - lr: 0.050000\n",
            "2022-06-17 09:30:28,180 epoch 15 - iter 276/469 - loss 0.00775839 - samples/sec: 79.97 - lr: 0.050000\n",
            "2022-06-17 09:30:46,877 epoch 15 - iter 322/469 - loss 0.00774087 - samples/sec: 78.76 - lr: 0.050000\n",
            "2022-06-17 09:31:05,570 epoch 15 - iter 368/469 - loss 0.00753370 - samples/sec: 78.78 - lr: 0.050000\n",
            "2022-06-17 09:31:24,562 epoch 15 - iter 414/469 - loss 0.00774438 - samples/sec: 77.54 - lr: 0.050000\n",
            "2022-06-17 09:31:43,311 epoch 15 - iter 460/469 - loss 0.00775267 - samples/sec: 78.55 - lr: 0.050000\n",
            "2022-06-17 09:31:46,920 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:31:46,923 EPOCH 15 done: loss 0.0078 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:32:11,223 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:32:11,278 DEV : loss 0.10129936039447784 - f1-score (micro avg)  0.9451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:32:11,738 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 09:32:11,741 saving best model\n",
            "2022-06-17 09:32:14,129 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:32:32,696 epoch 16 - iter 46/469 - loss 0.00759985 - samples/sec: 79.33 - lr: 0.050000\n",
            "2022-06-17 09:32:51,174 epoch 16 - iter 92/469 - loss 0.00743831 - samples/sec: 79.70 - lr: 0.050000\n",
            "2022-06-17 09:33:09,888 epoch 16 - iter 138/469 - loss 0.00812441 - samples/sec: 78.69 - lr: 0.050000\n",
            "2022-06-17 09:33:28,395 epoch 16 - iter 184/469 - loss 0.00793827 - samples/sec: 79.57 - lr: 0.050000\n",
            "2022-06-17 09:33:47,431 epoch 16 - iter 230/469 - loss 0.00727488 - samples/sec: 77.36 - lr: 0.050000\n",
            "2022-06-17 09:34:06,723 epoch 16 - iter 276/469 - loss 0.00726592 - samples/sec: 76.33 - lr: 0.050000\n",
            "2022-06-17 09:34:25,511 epoch 16 - iter 322/469 - loss 0.00809935 - samples/sec: 78.39 - lr: 0.050000\n",
            "2022-06-17 09:34:43,898 epoch 16 - iter 368/469 - loss 0.00804295 - samples/sec: 80.09 - lr: 0.050000\n",
            "2022-06-17 09:35:02,098 epoch 16 - iter 414/469 - loss 0.00762434 - samples/sec: 80.92 - lr: 0.050000\n",
            "2022-06-17 09:35:21,141 epoch 16 - iter 460/469 - loss 0.00760953 - samples/sec: 77.33 - lr: 0.050000\n",
            "2022-06-17 09:35:24,432 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:35:24,434 EPOCH 16 done: loss 0.0076 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:35:48,044 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:35:48,096 DEV : loss 0.10863196849822998 - f1-score (micro avg)  0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:35:48,554 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 09:35:48,557 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:36:06,983 epoch 17 - iter 46/469 - loss 0.00741944 - samples/sec: 79.93 - lr: 0.050000\n",
            "2022-06-17 09:36:25,577 epoch 17 - iter 92/469 - loss 0.00610798 - samples/sec: 79.20 - lr: 0.050000\n",
            "2022-06-17 09:36:43,941 epoch 17 - iter 138/469 - loss 0.00649623 - samples/sec: 80.19 - lr: 0.050000\n",
            "2022-06-17 09:37:02,365 epoch 17 - iter 184/469 - loss 0.00645018 - samples/sec: 79.93 - lr: 0.050000\n",
            "2022-06-17 09:37:21,129 epoch 17 - iter 230/469 - loss 0.00649915 - samples/sec: 78.48 - lr: 0.050000\n",
            "2022-06-17 09:37:39,125 epoch 17 - iter 276/469 - loss 0.00647293 - samples/sec: 81.83 - lr: 0.050000\n",
            "2022-06-17 09:37:57,995 epoch 17 - iter 322/469 - loss 0.00639933 - samples/sec: 78.04 - lr: 0.050000\n",
            "2022-06-17 09:38:16,043 epoch 17 - iter 368/469 - loss 0.00659308 - samples/sec: 81.59 - lr: 0.050000\n",
            "2022-06-17 09:38:34,461 epoch 17 - iter 414/469 - loss 0.00642044 - samples/sec: 79.95 - lr: 0.050000\n",
            "2022-06-17 09:38:53,616 epoch 17 - iter 460/469 - loss 0.00649496 - samples/sec: 76.88 - lr: 0.050000\n",
            "2022-06-17 09:38:57,082 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:38:57,084 EPOCH 17 done: loss 0.0066 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:39:19,565 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:39:19,619 DEV : loss 0.09911255538463593 - f1-score (micro avg)  0.9461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:39:20,076 BAD EPOCHS (no improvement): 0\n",
            "2022-06-17 09:39:20,079 saving best model\n",
            "2022-06-17 09:39:22,407 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:39:40,940 epoch 18 - iter 46/469 - loss 0.00491883 - samples/sec: 79.47 - lr: 0.050000\n",
            "2022-06-17 09:39:58,854 epoch 18 - iter 92/469 - loss 0.00524463 - samples/sec: 82.21 - lr: 0.050000\n",
            "2022-06-17 09:40:17,165 epoch 18 - iter 138/469 - loss 0.00504932 - samples/sec: 80.42 - lr: 0.050000\n",
            "2022-06-17 09:40:35,242 epoch 18 - iter 184/469 - loss 0.00578111 - samples/sec: 81.47 - lr: 0.050000\n",
            "2022-06-17 09:40:53,986 epoch 18 - iter 230/469 - loss 0.00569218 - samples/sec: 78.56 - lr: 0.050000\n",
            "2022-06-17 09:41:13,348 epoch 18 - iter 276/469 - loss 0.00560952 - samples/sec: 76.05 - lr: 0.050000\n",
            "2022-06-17 09:41:32,754 epoch 18 - iter 322/469 - loss 0.00591489 - samples/sec: 75.88 - lr: 0.050000\n",
            "2022-06-17 09:41:51,585 epoch 18 - iter 368/469 - loss 0.00628213 - samples/sec: 78.20 - lr: 0.050000\n",
            "2022-06-17 09:42:10,438 epoch 18 - iter 414/469 - loss 0.00624883 - samples/sec: 78.11 - lr: 0.050000\n",
            "2022-06-17 09:42:28,564 epoch 18 - iter 460/469 - loss 0.00622600 - samples/sec: 81.24 - lr: 0.050000\n",
            "2022-06-17 09:42:32,168 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:42:32,170 EPOCH 18 done: loss 0.0062 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:42:56,288 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:42:56,343 DEV : loss 0.12595795094966888 - f1-score (micro avg)  0.9405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:42:56,803 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 09:42:56,807 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:43:15,474 epoch 19 - iter 46/469 - loss 0.00315771 - samples/sec: 78.90 - lr: 0.050000\n",
            "2022-06-17 09:43:34,179 epoch 19 - iter 92/469 - loss 0.00386303 - samples/sec: 78.73 - lr: 0.050000\n",
            "2022-06-17 09:43:52,745 epoch 19 - iter 138/469 - loss 0.00390051 - samples/sec: 79.32 - lr: 0.050000\n",
            "2022-06-17 09:44:11,550 epoch 19 - iter 184/469 - loss 0.00377167 - samples/sec: 78.31 - lr: 0.050000\n",
            "2022-06-17 09:44:31,004 epoch 19 - iter 230/469 - loss 0.00387298 - samples/sec: 75.70 - lr: 0.050000\n",
            "2022-06-17 09:44:49,831 epoch 19 - iter 276/469 - loss 0.00443087 - samples/sec: 78.22 - lr: 0.050000\n",
            "2022-06-17 09:45:08,264 epoch 19 - iter 322/469 - loss 0.00459621 - samples/sec: 79.90 - lr: 0.050000\n",
            "2022-06-17 09:45:27,004 epoch 19 - iter 368/469 - loss 0.00487457 - samples/sec: 78.59 - lr: 0.050000\n",
            "2022-06-17 09:45:45,598 epoch 19 - iter 414/469 - loss 0.00494979 - samples/sec: 79.20 - lr: 0.050000\n",
            "2022-06-17 09:46:04,530 epoch 19 - iter 460/469 - loss 0.00509468 - samples/sec: 77.79 - lr: 0.050000\n",
            "2022-06-17 09:46:07,712 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:46:07,715 EPOCH 19 done: loss 0.0051 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:46:31,859 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:46:31,914 DEV : loss 0.12453508377075195 - f1-score (micro avg)  0.9378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:46:32,372 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 09:46:32,375 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:46:51,416 epoch 20 - iter 46/469 - loss 0.00606370 - samples/sec: 77.35 - lr: 0.050000\n",
            "2022-06-17 09:47:09,972 epoch 20 - iter 92/469 - loss 0.00489798 - samples/sec: 79.36 - lr: 0.050000\n",
            "2022-06-17 09:47:28,907 epoch 20 - iter 138/469 - loss 0.00507934 - samples/sec: 77.77 - lr: 0.050000\n",
            "2022-06-17 09:47:47,765 epoch 20 - iter 184/469 - loss 0.00547195 - samples/sec: 78.09 - lr: 0.050000\n",
            "2022-06-17 09:48:06,268 epoch 20 - iter 230/469 - loss 0.00550359 - samples/sec: 79.59 - lr: 0.050000\n",
            "2022-06-17 09:48:25,061 epoch 20 - iter 276/469 - loss 0.00549537 - samples/sec: 78.36 - lr: 0.050000\n",
            "2022-06-17 09:48:43,838 epoch 20 - iter 322/469 - loss 0.00542835 - samples/sec: 78.42 - lr: 0.050000\n",
            "2022-06-17 09:49:02,604 epoch 20 - iter 368/469 - loss 0.00563865 - samples/sec: 78.48 - lr: 0.050000\n",
            "2022-06-17 09:49:21,501 epoch 20 - iter 414/469 - loss 0.00565746 - samples/sec: 77.93 - lr: 0.050000\n",
            "2022-06-17 09:49:39,659 epoch 20 - iter 460/469 - loss 0.00543572 - samples/sec: 81.10 - lr: 0.050000\n",
            "2022-06-17 09:49:43,038 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:49:43,041 EPOCH 20 done: loss 0.0055 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:50:07,235 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:50:07,293 DEV : loss 0.125911146402359 - f1-score (micro avg)  0.9405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:50:07,762 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 09:50:07,766 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:50:26,152 epoch 21 - iter 46/469 - loss 0.00340412 - samples/sec: 80.11 - lr: 0.050000\n",
            "2022-06-17 09:50:44,835 epoch 21 - iter 92/469 - loss 0.00380340 - samples/sec: 78.82 - lr: 0.050000\n",
            "2022-06-17 09:51:03,474 epoch 21 - iter 138/469 - loss 0.00430822 - samples/sec: 79.00 - lr: 0.050000\n",
            "2022-06-17 09:51:22,671 epoch 21 - iter 184/469 - loss 0.00445809 - samples/sec: 76.71 - lr: 0.050000\n",
            "2022-06-17 09:51:41,287 epoch 21 - iter 230/469 - loss 0.00477563 - samples/sec: 79.11 - lr: 0.050000\n",
            "2022-06-17 09:51:59,884 epoch 21 - iter 276/469 - loss 0.00455834 - samples/sec: 79.19 - lr: 0.050000\n",
            "2022-06-17 09:52:18,602 epoch 21 - iter 322/469 - loss 0.00455958 - samples/sec: 78.67 - lr: 0.050000\n",
            "2022-06-17 09:52:37,660 epoch 21 - iter 368/469 - loss 0.00484177 - samples/sec: 77.27 - lr: 0.050000\n",
            "2022-06-17 09:52:56,228 epoch 21 - iter 414/469 - loss 0.00471709 - samples/sec: 79.31 - lr: 0.050000\n",
            "2022-06-17 09:53:15,033 epoch 21 - iter 460/469 - loss 0.00459655 - samples/sec: 78.31 - lr: 0.050000\n",
            "2022-06-17 09:53:18,710 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:53:18,712 EPOCH 21 done: loss 0.0047 - lr 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:53:41,609 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:53:41,668 DEV : loss 0.1391693353652954 - f1-score (micro avg)  0.9393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:53:42,134 Epoch    21: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-06-17 09:53:42,136 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 09:53:42,139 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:54:01,201 epoch 22 - iter 46/469 - loss 0.00289091 - samples/sec: 77.27 - lr: 0.025000\n",
            "2022-06-17 09:54:20,396 epoch 22 - iter 92/469 - loss 0.00377665 - samples/sec: 76.72 - lr: 0.025000\n",
            "2022-06-17 09:54:40,371 epoch 22 - iter 138/469 - loss 0.00395078 - samples/sec: 73.72 - lr: 0.025000\n",
            "2022-06-17 09:54:59,007 epoch 22 - iter 184/469 - loss 0.00367841 - samples/sec: 79.02 - lr: 0.025000\n",
            "2022-06-17 09:55:17,972 epoch 22 - iter 230/469 - loss 0.00346417 - samples/sec: 77.65 - lr: 0.025000\n",
            "2022-06-17 09:55:36,870 epoch 22 - iter 276/469 - loss 0.00324738 - samples/sec: 77.93 - lr: 0.025000\n",
            "2022-06-17 09:55:55,502 epoch 22 - iter 322/469 - loss 0.00317196 - samples/sec: 79.04 - lr: 0.025000\n",
            "2022-06-17 09:56:13,885 epoch 22 - iter 368/469 - loss 0.00293774 - samples/sec: 80.11 - lr: 0.025000\n",
            "2022-06-17 09:56:32,316 epoch 22 - iter 414/469 - loss 0.00292108 - samples/sec: 79.90 - lr: 0.025000\n",
            "2022-06-17 09:56:50,857 epoch 22 - iter 460/469 - loss 0.00303114 - samples/sec: 79.43 - lr: 0.025000\n",
            "2022-06-17 09:56:54,413 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:56:54,415 EPOCH 22 done: loss 0.0031 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:57:17,382 Evaluating as a multi-label problem: False\n",
            "2022-06-17 09:57:17,439 DEV : loss 0.1427735984325409 - f1-score (micro avg)  0.9451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 09:57:17,902 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 09:57:17,905 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 09:57:36,770 epoch 23 - iter 46/469 - loss 0.00303958 - samples/sec: 78.07 - lr: 0.025000\n",
            "2022-06-17 09:57:55,627 epoch 23 - iter 92/469 - loss 0.00290001 - samples/sec: 78.09 - lr: 0.025000\n",
            "2022-06-17 09:58:14,208 epoch 23 - iter 138/469 - loss 0.00237839 - samples/sec: 79.26 - lr: 0.025000\n",
            "2022-06-17 09:58:32,545 epoch 23 - iter 184/469 - loss 0.00242731 - samples/sec: 80.31 - lr: 0.025000\n",
            "2022-06-17 09:58:51,794 epoch 23 - iter 230/469 - loss 0.00249280 - samples/sec: 76.50 - lr: 0.025000\n",
            "2022-06-17 09:59:10,688 epoch 23 - iter 276/469 - loss 0.00271465 - samples/sec: 77.94 - lr: 0.025000\n",
            "2022-06-17 09:59:29,698 epoch 23 - iter 322/469 - loss 0.00257270 - samples/sec: 77.47 - lr: 0.025000\n",
            "2022-06-17 09:59:48,832 epoch 23 - iter 368/469 - loss 0.00242364 - samples/sec: 76.96 - lr: 0.025000\n",
            "2022-06-17 10:00:07,635 epoch 23 - iter 414/469 - loss 0.00237600 - samples/sec: 78.32 - lr: 0.025000\n",
            "2022-06-17 10:00:25,714 epoch 23 - iter 460/469 - loss 0.00234016 - samples/sec: 81.45 - lr: 0.025000\n",
            "2022-06-17 10:00:28,949 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:00:28,951 EPOCH 23 done: loss 0.0024 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:00:53,249 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:00:53,303 DEV : loss 0.1388322114944458 - f1-score (micro avg)  0.9429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:00:53,766 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 10:00:53,770 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:01:12,308 epoch 24 - iter 46/469 - loss 0.00317625 - samples/sec: 79.45 - lr: 0.025000\n",
            "2022-06-17 10:01:31,209 epoch 24 - iter 92/469 - loss 0.00264753 - samples/sec: 77.91 - lr: 0.025000\n",
            "2022-06-17 10:01:49,695 epoch 24 - iter 138/469 - loss 0.00268190 - samples/sec: 79.66 - lr: 0.025000\n",
            "2022-06-17 10:02:08,777 epoch 24 - iter 184/469 - loss 0.00214397 - samples/sec: 77.17 - lr: 0.025000\n",
            "2022-06-17 10:02:27,300 epoch 24 - iter 230/469 - loss 0.00259723 - samples/sec: 79.50 - lr: 0.025000\n",
            "2022-06-17 10:02:47,231 epoch 24 - iter 276/469 - loss 0.00237896 - samples/sec: 73.89 - lr: 0.025000\n",
            "2022-06-17 10:03:05,541 epoch 24 - iter 322/469 - loss 0.00231399 - samples/sec: 80.43 - lr: 0.025000\n",
            "2022-06-17 10:03:24,657 epoch 24 - iter 368/469 - loss 0.00226833 - samples/sec: 77.03 - lr: 0.025000\n",
            "2022-06-17 10:03:43,723 epoch 24 - iter 414/469 - loss 0.00215714 - samples/sec: 77.23 - lr: 0.025000\n",
            "2022-06-17 10:04:01,928 epoch 24 - iter 460/469 - loss 0.00222054 - samples/sec: 80.89 - lr: 0.025000\n",
            "2022-06-17 10:04:05,318 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:04:05,320 EPOCH 24 done: loss 0.0022 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:04:29,695 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:04:29,749 DEV : loss 0.14742818474769592 - f1-score (micro avg)  0.9395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:04:30,209 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 10:04:30,213 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:04:49,263 epoch 25 - iter 46/469 - loss 0.00256894 - samples/sec: 77.32 - lr: 0.025000\n",
            "2022-06-17 10:05:07,390 epoch 25 - iter 92/469 - loss 0.00331915 - samples/sec: 81.24 - lr: 0.025000\n",
            "2022-06-17 10:05:26,475 epoch 25 - iter 138/469 - loss 0.00301469 - samples/sec: 77.16 - lr: 0.025000\n",
            "2022-06-17 10:05:45,252 epoch 25 - iter 184/469 - loss 0.00262722 - samples/sec: 78.43 - lr: 0.025000\n",
            "2022-06-17 10:06:03,977 epoch 25 - iter 230/469 - loss 0.00239419 - samples/sec: 78.64 - lr: 0.025000\n",
            "2022-06-17 10:06:22,990 epoch 25 - iter 276/469 - loss 0.00211161 - samples/sec: 77.46 - lr: 0.025000\n",
            "2022-06-17 10:06:41,708 epoch 25 - iter 322/469 - loss 0.00242135 - samples/sec: 78.67 - lr: 0.025000\n",
            "2022-06-17 10:07:00,648 epoch 25 - iter 368/469 - loss 0.00234359 - samples/sec: 77.75 - lr: 0.025000\n",
            "2022-06-17 10:07:19,866 epoch 25 - iter 414/469 - loss 0.00235931 - samples/sec: 76.63 - lr: 0.025000\n",
            "2022-06-17 10:07:38,299 epoch 25 - iter 460/469 - loss 0.00226553 - samples/sec: 79.89 - lr: 0.025000\n",
            "2022-06-17 10:07:41,727 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:07:41,729 EPOCH 25 done: loss 0.0023 - lr 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:08:06,003 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:08:06,060 DEV : loss 0.15061542391777039 - f1-score (micro avg)  0.9423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:08:06,530 Epoch    25: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-06-17 10:08:06,532 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 10:08:06,536 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:08:25,624 epoch 26 - iter 46/469 - loss 0.00106342 - samples/sec: 77.16 - lr: 0.012500\n",
            "2022-06-17 10:08:44,923 epoch 26 - iter 92/469 - loss 0.00190132 - samples/sec: 76.30 - lr: 0.012500\n",
            "2022-06-17 10:09:03,970 epoch 26 - iter 138/469 - loss 0.00162489 - samples/sec: 77.32 - lr: 0.012500\n",
            "2022-06-17 10:09:22,719 epoch 26 - iter 184/469 - loss 0.00160492 - samples/sec: 78.55 - lr: 0.012500\n",
            "2022-06-17 10:09:41,627 epoch 26 - iter 230/469 - loss 0.00175107 - samples/sec: 77.88 - lr: 0.012500\n",
            "2022-06-17 10:10:00,251 epoch 26 - iter 276/469 - loss 0.00173637 - samples/sec: 79.07 - lr: 0.012500\n",
            "2022-06-17 10:10:18,958 epoch 26 - iter 322/469 - loss 0.00174378 - samples/sec: 78.72 - lr: 0.012500\n",
            "2022-06-17 10:10:37,631 epoch 26 - iter 368/469 - loss 0.00173036 - samples/sec: 78.86 - lr: 0.012500\n",
            "2022-06-17 10:10:56,443 epoch 26 - iter 414/469 - loss 0.00174723 - samples/sec: 78.28 - lr: 0.012500\n",
            "2022-06-17 10:11:15,052 epoch 26 - iter 460/469 - loss 0.00168744 - samples/sec: 79.14 - lr: 0.012500\n",
            "2022-06-17 10:11:18,311 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:11:18,313 EPOCH 26 done: loss 0.0017 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:11:41,353 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:11:41,411 DEV : loss 0.1478821039199829 - f1-score (micro avg)  0.9429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:11:41,873 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 10:11:41,877 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:12:00,947 epoch 27 - iter 46/469 - loss 0.00131955 - samples/sec: 77.23 - lr: 0.012500\n",
            "2022-06-17 10:12:19,409 epoch 27 - iter 92/469 - loss 0.00177559 - samples/sec: 79.77 - lr: 0.012500\n",
            "2022-06-17 10:12:38,444 epoch 27 - iter 138/469 - loss 0.00204185 - samples/sec: 77.36 - lr: 0.012500\n",
            "2022-06-17 10:12:57,727 epoch 27 - iter 184/469 - loss 0.00200246 - samples/sec: 76.37 - lr: 0.012500\n",
            "2022-06-17 10:13:16,312 epoch 27 - iter 230/469 - loss 0.00170019 - samples/sec: 79.24 - lr: 0.012500\n",
            "2022-06-17 10:13:34,693 epoch 27 - iter 276/469 - loss 0.00154839 - samples/sec: 80.12 - lr: 0.012500\n",
            "2022-06-17 10:13:53,301 epoch 27 - iter 322/469 - loss 0.00169497 - samples/sec: 79.14 - lr: 0.012500\n",
            "2022-06-17 10:14:12,069 epoch 27 - iter 368/469 - loss 0.00154409 - samples/sec: 78.47 - lr: 0.012500\n",
            "2022-06-17 10:14:30,683 epoch 27 - iter 414/469 - loss 0.00156117 - samples/sec: 79.11 - lr: 0.012500\n",
            "2022-06-17 10:14:49,279 epoch 27 - iter 460/469 - loss 0.00143059 - samples/sec: 79.19 - lr: 0.012500\n",
            "2022-06-17 10:14:52,726 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:14:52,728 EPOCH 27 done: loss 0.0014 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:15:16,586 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:15:16,638 DEV : loss 0.15215998888015747 - f1-score (micro avg)  0.9423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:15:17,090 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 10:15:17,095 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:15:35,945 epoch 28 - iter 46/469 - loss 0.00069056 - samples/sec: 78.14 - lr: 0.012500\n",
            "2022-06-17 10:15:54,165 epoch 28 - iter 92/469 - loss 0.00049349 - samples/sec: 80.82 - lr: 0.012500\n",
            "2022-06-17 10:16:12,165 epoch 28 - iter 138/469 - loss 0.00085874 - samples/sec: 81.81 - lr: 0.012500\n",
            "2022-06-17 10:16:30,293 epoch 28 - iter 184/469 - loss 0.00095022 - samples/sec: 81.23 - lr: 0.012500\n",
            "2022-06-17 10:16:48,391 epoch 28 - iter 230/469 - loss 0.00101356 - samples/sec: 81.37 - lr: 0.012500\n",
            "2022-06-17 10:17:06,734 epoch 28 - iter 276/469 - loss 0.00088501 - samples/sec: 80.28 - lr: 0.012500\n",
            "2022-06-17 10:17:25,799 epoch 28 - iter 322/469 - loss 0.00118739 - samples/sec: 77.24 - lr: 0.012500\n",
            "2022-06-17 10:17:44,595 epoch 28 - iter 368/469 - loss 0.00114273 - samples/sec: 78.35 - lr: 0.012500\n",
            "2022-06-17 10:18:02,991 epoch 28 - iter 414/469 - loss 0.00109517 - samples/sec: 80.05 - lr: 0.012500\n",
            "2022-06-17 10:18:21,336 epoch 28 - iter 460/469 - loss 0.00126040 - samples/sec: 80.28 - lr: 0.012500\n",
            "2022-06-17 10:18:24,646 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:18:24,648 EPOCH 28 done: loss 0.0012 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:18:48,251 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:18:48,305 DEV : loss 0.1583978235721588 - f1-score (micro avg)  0.9433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:18:48,762 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 10:18:48,765 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:19:07,346 epoch 29 - iter 46/469 - loss 0.00151355 - samples/sec: 79.27 - lr: 0.012500\n",
            "2022-06-17 10:19:25,935 epoch 29 - iter 92/469 - loss 0.00137849 - samples/sec: 79.22 - lr: 0.012500\n",
            "2022-06-17 10:19:44,507 epoch 29 - iter 138/469 - loss 0.00108019 - samples/sec: 79.29 - lr: 0.012500\n",
            "2022-06-17 10:20:02,618 epoch 29 - iter 184/469 - loss 0.00115661 - samples/sec: 81.31 - lr: 0.012500\n",
            "2022-06-17 10:20:21,046 epoch 29 - iter 230/469 - loss 0.00109815 - samples/sec: 79.91 - lr: 0.012500\n",
            "2022-06-17 10:20:39,567 epoch 29 - iter 276/469 - loss 0.00123853 - samples/sec: 79.51 - lr: 0.012500\n",
            "2022-06-17 10:20:57,808 epoch 29 - iter 322/469 - loss 0.00132916 - samples/sec: 80.73 - lr: 0.012500\n",
            "2022-06-17 10:21:16,385 epoch 29 - iter 368/469 - loss 0.00136220 - samples/sec: 79.27 - lr: 0.012500\n",
            "2022-06-17 10:21:35,061 epoch 29 - iter 414/469 - loss 0.00123245 - samples/sec: 78.86 - lr: 0.012500\n",
            "2022-06-17 10:21:53,567 epoch 29 - iter 460/469 - loss 0.00124997 - samples/sec: 79.58 - lr: 0.012500\n",
            "2022-06-17 10:21:57,029 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:21:57,031 EPOCH 29 done: loss 0.0012 - lr 0.012500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:22:21,272 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:22:21,327 DEV : loss 0.15556968748569489 - f1-score (micro avg)  0.9453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:22:21,784 Epoch    29: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-06-17 10:22:21,787 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 10:22:21,790 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:22:40,235 epoch 30 - iter 46/469 - loss 0.00090196 - samples/sec: 79.85 - lr: 0.006250\n",
            "2022-06-17 10:22:58,959 epoch 30 - iter 92/469 - loss 0.00069397 - samples/sec: 78.66 - lr: 0.006250\n",
            "2022-06-17 10:23:17,168 epoch 30 - iter 138/469 - loss 0.00085360 - samples/sec: 80.87 - lr: 0.006250\n",
            "2022-06-17 10:23:36,202 epoch 30 - iter 184/469 - loss 0.00088915 - samples/sec: 77.37 - lr: 0.006250\n",
            "2022-06-17 10:23:54,936 epoch 30 - iter 230/469 - loss 0.00091601 - samples/sec: 78.61 - lr: 0.006250\n",
            "2022-06-17 10:24:14,398 epoch 30 - iter 276/469 - loss 0.00089818 - samples/sec: 75.67 - lr: 0.006250\n",
            "2022-06-17 10:24:32,554 epoch 30 - iter 322/469 - loss 0.00098743 - samples/sec: 81.11 - lr: 0.006250\n",
            "2022-06-17 10:24:51,066 epoch 30 - iter 368/469 - loss 0.00089968 - samples/sec: 79.55 - lr: 0.006250\n",
            "2022-06-17 10:25:10,286 epoch 30 - iter 414/469 - loss 0.00108138 - samples/sec: 76.62 - lr: 0.006250\n",
            "2022-06-17 10:25:28,824 epoch 30 - iter 460/469 - loss 0.00102423 - samples/sec: 79.44 - lr: 0.006250\n",
            "2022-06-17 10:25:32,578 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:25:32,580 EPOCH 30 done: loss 0.0011 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:25:55,485 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:25:55,545 DEV : loss 0.16040655970573425 - f1-score (micro avg)  0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:25:56,015 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 10:25:56,020 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:26:15,425 epoch 31 - iter 46/469 - loss 0.00188820 - samples/sec: 75.90 - lr: 0.006250\n",
            "2022-06-17 10:26:34,175 epoch 31 - iter 92/469 - loss 0.00137322 - samples/sec: 78.54 - lr: 0.006250\n",
            "2022-06-17 10:26:52,560 epoch 31 - iter 138/469 - loss 0.00139687 - samples/sec: 80.10 - lr: 0.006250\n",
            "2022-06-17 10:27:11,233 epoch 31 - iter 184/469 - loss 0.00109235 - samples/sec: 78.86 - lr: 0.006250\n",
            "2022-06-17 10:27:29,805 epoch 31 - iter 230/469 - loss 0.00113167 - samples/sec: 79.29 - lr: 0.006250\n",
            "2022-06-17 10:27:48,771 epoch 31 - iter 276/469 - loss 0.00110862 - samples/sec: 77.65 - lr: 0.006250\n",
            "2022-06-17 10:28:08,771 epoch 31 - iter 322/469 - loss 0.00097747 - samples/sec: 73.62 - lr: 0.006250\n",
            "2022-06-17 10:28:27,185 epoch 31 - iter 368/469 - loss 0.00099334 - samples/sec: 79.98 - lr: 0.006250\n",
            "2022-06-17 10:28:45,466 epoch 31 - iter 414/469 - loss 0.00116487 - samples/sec: 80.55 - lr: 0.006250\n",
            "2022-06-17 10:29:04,392 epoch 31 - iter 460/469 - loss 0.00114458 - samples/sec: 77.81 - lr: 0.006250\n",
            "2022-06-17 10:29:07,712 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:29:07,713 EPOCH 31 done: loss 0.0011 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:29:30,649 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:29:30,708 DEV : loss 0.1576801836490631 - f1-score (micro avg)  0.9461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:29:31,172 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 10:29:31,175 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:29:49,698 epoch 32 - iter 46/469 - loss 0.00138890 - samples/sec: 79.52 - lr: 0.006250\n",
            "2022-06-17 10:30:08,176 epoch 32 - iter 92/469 - loss 0.00085594 - samples/sec: 79.69 - lr: 0.006250\n",
            "2022-06-17 10:30:26,984 epoch 32 - iter 138/469 - loss 0.00120325 - samples/sec: 78.30 - lr: 0.006250\n",
            "2022-06-17 10:30:45,886 epoch 32 - iter 184/469 - loss 0.00126939 - samples/sec: 77.91 - lr: 0.006250\n",
            "2022-06-17 10:31:05,020 epoch 32 - iter 230/469 - loss 0.00114588 - samples/sec: 76.96 - lr: 0.006250\n",
            "2022-06-17 10:31:23,808 epoch 32 - iter 276/469 - loss 0.00101996 - samples/sec: 78.38 - lr: 0.006250\n",
            "2022-06-17 10:31:42,583 epoch 32 - iter 322/469 - loss 0.00105495 - samples/sec: 78.43 - lr: 0.006250\n",
            "2022-06-17 10:32:01,313 epoch 32 - iter 368/469 - loss 0.00105029 - samples/sec: 78.63 - lr: 0.006250\n",
            "2022-06-17 10:32:19,722 epoch 32 - iter 414/469 - loss 0.00116511 - samples/sec: 79.99 - lr: 0.006250\n",
            "2022-06-17 10:32:38,813 epoch 32 - iter 460/469 - loss 0.00111799 - samples/sec: 77.13 - lr: 0.006250\n",
            "2022-06-17 10:32:42,267 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:32:42,269 EPOCH 32 done: loss 0.0011 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:33:06,437 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:33:06,493 DEV : loss 0.1598232239484787 - f1-score (micro avg)  0.9456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:33:06,949 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 10:33:06,953 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:33:25,905 epoch 33 - iter 46/469 - loss 0.00192904 - samples/sec: 77.71 - lr: 0.006250\n",
            "2022-06-17 10:33:44,428 epoch 33 - iter 92/469 - loss 0.00143175 - samples/sec: 79.51 - lr: 0.006250\n",
            "2022-06-17 10:34:03,230 epoch 33 - iter 138/469 - loss 0.00130568 - samples/sec: 78.32 - lr: 0.006250\n",
            "2022-06-17 10:34:22,127 epoch 33 - iter 184/469 - loss 0.00118022 - samples/sec: 77.93 - lr: 0.006250\n",
            "2022-06-17 10:34:40,875 epoch 33 - iter 230/469 - loss 0.00109646 - samples/sec: 78.55 - lr: 0.006250\n",
            "2022-06-17 10:34:59,478 epoch 33 - iter 276/469 - loss 0.00116423 - samples/sec: 79.17 - lr: 0.006250\n",
            "2022-06-17 10:35:18,443 epoch 33 - iter 322/469 - loss 0.00114455 - samples/sec: 77.65 - lr: 0.006250\n",
            "2022-06-17 10:35:37,016 epoch 33 - iter 368/469 - loss 0.00102723 - samples/sec: 79.29 - lr: 0.006250\n",
            "2022-06-17 10:35:55,961 epoch 33 - iter 414/469 - loss 0.00106972 - samples/sec: 77.73 - lr: 0.006250\n",
            "2022-06-17 10:36:14,573 epoch 33 - iter 460/469 - loss 0.00108634 - samples/sec: 79.12 - lr: 0.006250\n",
            "2022-06-17 10:36:18,032 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:36:18,034 EPOCH 33 done: loss 0.0011 - lr 0.006250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:36:42,256 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:36:42,312 DEV : loss 0.16121862828731537 - f1-score (micro avg)  0.9459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:36:42,777 Epoch    33: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-06-17 10:36:42,779 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 10:36:42,781 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:37:01,660 epoch 34 - iter 46/469 - loss 0.00136849 - samples/sec: 78.03 - lr: 0.003125\n",
            "2022-06-17 10:37:21,301 epoch 34 - iter 92/469 - loss 0.00099582 - samples/sec: 74.97 - lr: 0.003125\n",
            "2022-06-17 10:37:39,712 epoch 34 - iter 138/469 - loss 0.00080413 - samples/sec: 79.99 - lr: 0.003125\n",
            "2022-06-17 10:37:58,787 epoch 34 - iter 184/469 - loss 0.00085800 - samples/sec: 77.20 - lr: 0.003125\n",
            "2022-06-17 10:38:17,880 epoch 34 - iter 230/469 - loss 0.00080405 - samples/sec: 77.13 - lr: 0.003125\n",
            "2022-06-17 10:38:36,103 epoch 34 - iter 276/469 - loss 0.00072022 - samples/sec: 80.81 - lr: 0.003125\n",
            "2022-06-17 10:38:54,657 epoch 34 - iter 322/469 - loss 0.00080521 - samples/sec: 79.37 - lr: 0.003125\n",
            "2022-06-17 10:39:13,341 epoch 34 - iter 368/469 - loss 0.00085867 - samples/sec: 78.82 - lr: 0.003125\n",
            "2022-06-17 10:39:31,725 epoch 34 - iter 414/469 - loss 0.00093041 - samples/sec: 80.11 - lr: 0.003125\n",
            "2022-06-17 10:39:50,372 epoch 34 - iter 460/469 - loss 0.00095688 - samples/sec: 78.97 - lr: 0.003125\n",
            "2022-06-17 10:39:53,982 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:39:53,984 EPOCH 34 done: loss 0.0009 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:40:18,252 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:40:18,309 DEV : loss 0.16081681847572327 - f1-score (micro avg)  0.9452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:40:18,775 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 10:40:18,778 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:40:37,325 epoch 35 - iter 46/469 - loss 0.00081484 - samples/sec: 79.41 - lr: 0.003125\n",
            "2022-06-17 10:40:56,657 epoch 35 - iter 92/469 - loss 0.00132948 - samples/sec: 76.18 - lr: 0.003125\n",
            "2022-06-17 10:41:15,683 epoch 35 - iter 138/469 - loss 0.00093095 - samples/sec: 77.40 - lr: 0.003125\n",
            "2022-06-17 10:41:34,192 epoch 35 - iter 184/469 - loss 0.00100761 - samples/sec: 79.57 - lr: 0.003125\n",
            "2022-06-17 10:41:53,087 epoch 35 - iter 230/469 - loss 0.00105164 - samples/sec: 77.94 - lr: 0.003125\n",
            "2022-06-17 10:42:11,706 epoch 35 - iter 276/469 - loss 0.00096923 - samples/sec: 79.09 - lr: 0.003125\n",
            "2022-06-17 10:42:30,289 epoch 35 - iter 322/469 - loss 0.00088326 - samples/sec: 79.25 - lr: 0.003125\n",
            "2022-06-17 10:42:48,924 epoch 35 - iter 368/469 - loss 0.00087231 - samples/sec: 79.03 - lr: 0.003125\n",
            "2022-06-17 10:43:07,723 epoch 35 - iter 414/469 - loss 0.00089671 - samples/sec: 78.34 - lr: 0.003125\n",
            "2022-06-17 10:43:26,330 epoch 35 - iter 460/469 - loss 0.00088519 - samples/sec: 79.15 - lr: 0.003125\n",
            "2022-06-17 10:43:29,861 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:43:29,863 EPOCH 35 done: loss 0.0009 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:43:52,740 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:43:52,797 DEV : loss 0.16388776898384094 - f1-score (micro avg)  0.9449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:43:53,257 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 10:43:53,260 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:44:12,458 epoch 36 - iter 46/469 - loss 0.00313980 - samples/sec: 76.72 - lr: 0.003125\n",
            "2022-06-17 10:44:31,473 epoch 36 - iter 92/469 - loss 0.00198851 - samples/sec: 77.45 - lr: 0.003125\n",
            "2022-06-17 10:44:50,453 epoch 36 - iter 138/469 - loss 0.00172514 - samples/sec: 77.59 - lr: 0.003125\n",
            "2022-06-17 10:45:09,629 epoch 36 - iter 184/469 - loss 0.00136691 - samples/sec: 76.80 - lr: 0.003125\n",
            "2022-06-17 10:45:28,050 epoch 36 - iter 230/469 - loss 0.00116423 - samples/sec: 79.94 - lr: 0.003125\n",
            "2022-06-17 10:45:46,550 epoch 36 - iter 276/469 - loss 0.00141134 - samples/sec: 79.60 - lr: 0.003125\n",
            "2022-06-17 10:46:05,037 epoch 36 - iter 322/469 - loss 0.00138466 - samples/sec: 79.65 - lr: 0.003125\n",
            "2022-06-17 10:46:23,617 epoch 36 - iter 368/469 - loss 0.00130851 - samples/sec: 79.26 - lr: 0.003125\n",
            "2022-06-17 10:46:42,648 epoch 36 - iter 414/469 - loss 0.00126000 - samples/sec: 77.38 - lr: 0.003125\n",
            "2022-06-17 10:47:01,355 epoch 36 - iter 460/469 - loss 0.00123916 - samples/sec: 78.72 - lr: 0.003125\n",
            "2022-06-17 10:47:04,753 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:47:04,756 EPOCH 36 done: loss 0.0012 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:47:29,135 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:47:29,193 DEV : loss 0.16377849876880646 - f1-score (micro avg)  0.9449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:47:29,650 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 10:47:29,653 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:47:48,726 epoch 37 - iter 46/469 - loss 0.00058128 - samples/sec: 77.23 - lr: 0.003125\n",
            "2022-06-17 10:48:06,998 epoch 37 - iter 92/469 - loss 0.00047753 - samples/sec: 80.59 - lr: 0.003125\n",
            "2022-06-17 10:48:25,467 epoch 37 - iter 138/469 - loss 0.00085655 - samples/sec: 79.74 - lr: 0.003125\n",
            "2022-06-17 10:48:43,713 epoch 37 - iter 184/469 - loss 0.00087634 - samples/sec: 80.71 - lr: 0.003125\n",
            "2022-06-17 10:49:02,646 epoch 37 - iter 230/469 - loss 0.00082961 - samples/sec: 77.78 - lr: 0.003125\n",
            "2022-06-17 10:49:22,111 epoch 37 - iter 276/469 - loss 0.00087782 - samples/sec: 75.65 - lr: 0.003125\n",
            "2022-06-17 10:49:40,886 epoch 37 - iter 322/469 - loss 0.00086319 - samples/sec: 78.44 - lr: 0.003125\n",
            "2022-06-17 10:49:59,694 epoch 37 - iter 368/469 - loss 0.00100032 - samples/sec: 78.30 - lr: 0.003125\n",
            "2022-06-17 10:50:18,511 epoch 37 - iter 414/469 - loss 0.00091688 - samples/sec: 78.26 - lr: 0.003125\n",
            "2022-06-17 10:50:37,132 epoch 37 - iter 460/469 - loss 0.00083262 - samples/sec: 79.08 - lr: 0.003125\n",
            "2022-06-17 10:50:40,634 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:50:40,636 EPOCH 37 done: loss 0.0009 - lr 0.003125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:51:04,997 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:51:05,053 DEV : loss 0.16497555375099182 - f1-score (micro avg)  0.9448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:51:05,519 Epoch    37: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-06-17 10:51:05,521 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 10:51:05,526 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:51:23,936 epoch 38 - iter 46/469 - loss 0.00051191 - samples/sec: 80.00 - lr: 0.001563\n",
            "2022-06-17 10:51:42,623 epoch 38 - iter 92/469 - loss 0.00061029 - samples/sec: 78.81 - lr: 0.001563\n",
            "2022-06-17 10:52:01,785 epoch 38 - iter 138/469 - loss 0.00080662 - samples/sec: 76.85 - lr: 0.001563\n",
            "2022-06-17 10:52:20,278 epoch 38 - iter 184/469 - loss 0.00082184 - samples/sec: 79.64 - lr: 0.001563\n",
            "2022-06-17 10:52:38,845 epoch 38 - iter 230/469 - loss 0.00072495 - samples/sec: 79.31 - lr: 0.001563\n",
            "2022-06-17 10:52:58,433 epoch 38 - iter 276/469 - loss 0.00077425 - samples/sec: 75.18 - lr: 0.001563\n",
            "2022-06-17 10:53:17,094 epoch 38 - iter 322/469 - loss 0.00079153 - samples/sec: 78.91 - lr: 0.001563\n",
            "2022-06-17 10:53:35,906 epoch 38 - iter 368/469 - loss 0.00075337 - samples/sec: 78.29 - lr: 0.001563\n",
            "2022-06-17 10:53:54,328 epoch 38 - iter 414/469 - loss 0.00092769 - samples/sec: 79.94 - lr: 0.001563\n",
            "2022-06-17 10:54:12,925 epoch 38 - iter 460/469 - loss 0.00088922 - samples/sec: 79.19 - lr: 0.001563\n",
            "2022-06-17 10:54:16,380 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:54:16,382 EPOCH 38 done: loss 0.0009 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:54:40,679 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:54:40,735 DEV : loss 0.16435116529464722 - f1-score (micro avg)  0.9438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:54:41,197 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 10:54:41,200 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:54:59,866 epoch 39 - iter 46/469 - loss 0.00098950 - samples/sec: 78.91 - lr: 0.001563\n",
            "2022-06-17 10:55:18,854 epoch 39 - iter 92/469 - loss 0.00096611 - samples/sec: 77.56 - lr: 0.001563\n",
            "2022-06-17 10:55:38,179 epoch 39 - iter 138/469 - loss 0.00088631 - samples/sec: 76.20 - lr: 0.001563\n",
            "2022-06-17 10:55:57,093 epoch 39 - iter 184/469 - loss 0.00083681 - samples/sec: 77.86 - lr: 0.001563\n",
            "2022-06-17 10:56:15,963 epoch 39 - iter 230/469 - loss 0.00083919 - samples/sec: 78.04 - lr: 0.001563\n",
            "2022-06-17 10:56:34,677 epoch 39 - iter 276/469 - loss 0.00082875 - samples/sec: 78.69 - lr: 0.001563\n",
            "2022-06-17 10:56:53,304 epoch 39 - iter 322/469 - loss 0.00080846 - samples/sec: 79.06 - lr: 0.001563\n",
            "2022-06-17 10:57:11,753 epoch 39 - iter 368/469 - loss 0.00076308 - samples/sec: 79.83 - lr: 0.001563\n",
            "2022-06-17 10:57:30,234 epoch 39 - iter 414/469 - loss 0.00086671 - samples/sec: 79.68 - lr: 0.001563\n",
            "2022-06-17 10:57:49,116 epoch 39 - iter 460/469 - loss 0.00094567 - samples/sec: 77.99 - lr: 0.001563\n",
            "2022-06-17 10:57:52,455 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:57:52,458 EPOCH 39 done: loss 0.0009 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:58:15,552 Evaluating as a multi-label problem: False\n",
            "2022-06-17 10:58:15,608 DEV : loss 0.1650353968143463 - f1-score (micro avg)  0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 10:58:16,070 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 10:58:16,074 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 10:58:34,677 epoch 40 - iter 46/469 - loss 0.00173060 - samples/sec: 79.17 - lr: 0.001563\n",
            "2022-06-17 10:58:53,821 epoch 40 - iter 92/469 - loss 0.00148271 - samples/sec: 76.93 - lr: 0.001563\n",
            "2022-06-17 10:59:12,153 epoch 40 - iter 138/469 - loss 0.00118464 - samples/sec: 80.33 - lr: 0.001563\n",
            "2022-06-17 10:59:31,154 epoch 40 - iter 184/469 - loss 0.00093404 - samples/sec: 77.51 - lr: 0.001563\n",
            "2022-06-17 10:59:49,834 epoch 40 - iter 230/469 - loss 0.00083552 - samples/sec: 78.83 - lr: 0.001563\n",
            "2022-06-17 11:00:08,700 epoch 40 - iter 276/469 - loss 0.00092881 - samples/sec: 78.06 - lr: 0.001563\n",
            "2022-06-17 11:00:27,462 epoch 40 - iter 322/469 - loss 0.00109075 - samples/sec: 78.49 - lr: 0.001563\n",
            "2022-06-17 11:00:46,093 epoch 40 - iter 368/469 - loss 0.00106494 - samples/sec: 79.04 - lr: 0.001563\n",
            "2022-06-17 11:01:04,998 epoch 40 - iter 414/469 - loss 0.00100929 - samples/sec: 77.90 - lr: 0.001563\n",
            "2022-06-17 11:01:24,380 epoch 40 - iter 460/469 - loss 0.00096570 - samples/sec: 75.98 - lr: 0.001563\n",
            "2022-06-17 11:01:29,050 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:01:29,052 EPOCH 40 done: loss 0.0009 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:01:52,227 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:01:52,284 DEV : loss 0.16567803919315338 - f1-score (micro avg)  0.9441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:01:52,750 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 11:01:52,754 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:02:11,501 epoch 41 - iter 46/469 - loss 0.00053587 - samples/sec: 78.56 - lr: 0.001563\n",
            "2022-06-17 11:02:30,557 epoch 41 - iter 92/469 - loss 0.00051604 - samples/sec: 77.28 - lr: 0.001563\n",
            "2022-06-17 11:02:49,338 epoch 41 - iter 138/469 - loss 0.00075682 - samples/sec: 78.41 - lr: 0.001563\n",
            "2022-06-17 11:03:08,569 epoch 41 - iter 184/469 - loss 0.00072781 - samples/sec: 76.58 - lr: 0.001563\n",
            "2022-06-17 11:03:26,911 epoch 41 - iter 230/469 - loss 0.00077078 - samples/sec: 80.29 - lr: 0.001563\n",
            "2022-06-17 11:03:45,610 epoch 41 - iter 276/469 - loss 0.00096349 - samples/sec: 78.76 - lr: 0.001563\n",
            "2022-06-17 11:04:04,065 epoch 41 - iter 322/469 - loss 0.00091321 - samples/sec: 79.80 - lr: 0.001563\n",
            "2022-06-17 11:04:22,753 epoch 41 - iter 368/469 - loss 0.00090696 - samples/sec: 78.80 - lr: 0.001563\n",
            "2022-06-17 11:04:41,982 epoch 41 - iter 414/469 - loss 0.00083786 - samples/sec: 76.58 - lr: 0.001563\n",
            "2022-06-17 11:05:00,741 epoch 41 - iter 460/469 - loss 0.00083156 - samples/sec: 78.51 - lr: 0.001563\n",
            "2022-06-17 11:05:04,531 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:05:04,533 EPOCH 41 done: loss 0.0008 - lr 0.001563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:05:28,939 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:05:28,996 DEV : loss 0.16575579345226288 - f1-score (micro avg)  0.9439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:05:29,461 Epoch    41: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-06-17 11:05:29,464 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 11:05:29,467 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:05:48,104 epoch 42 - iter 46/469 - loss 0.00095404 - samples/sec: 79.03 - lr: 0.000781\n",
            "2022-06-17 11:06:06,695 epoch 42 - iter 92/469 - loss 0.00112458 - samples/sec: 79.21 - lr: 0.000781\n",
            "2022-06-17 11:06:25,319 epoch 42 - iter 138/469 - loss 0.00137366 - samples/sec: 79.07 - lr: 0.000781\n",
            "2022-06-17 11:06:45,139 epoch 42 - iter 184/469 - loss 0.00122910 - samples/sec: 74.30 - lr: 0.000781\n",
            "2022-06-17 11:07:03,870 epoch 42 - iter 230/469 - loss 0.00122736 - samples/sec: 78.62 - lr: 0.000781\n",
            "2022-06-17 11:07:23,071 epoch 42 - iter 276/469 - loss 0.00108837 - samples/sec: 76.69 - lr: 0.000781\n",
            "2022-06-17 11:07:41,933 epoch 42 - iter 322/469 - loss 0.00099550 - samples/sec: 78.07 - lr: 0.000781\n",
            "2022-06-17 11:08:00,172 epoch 42 - iter 368/469 - loss 0.00113119 - samples/sec: 80.74 - lr: 0.000781\n",
            "2022-06-17 11:08:19,288 epoch 42 - iter 414/469 - loss 0.00103245 - samples/sec: 77.04 - lr: 0.000781\n",
            "2022-06-17 11:08:38,097 epoch 42 - iter 460/469 - loss 0.00119194 - samples/sec: 78.29 - lr: 0.000781\n",
            "2022-06-17 11:08:41,472 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:08:41,474 EPOCH 42 done: loss 0.0012 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:09:05,737 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:09:05,793 DEV : loss 0.1660126894712448 - f1-score (micro avg)  0.9438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:09:06,259 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 11:09:06,263 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:09:25,053 epoch 43 - iter 46/469 - loss 0.00030039 - samples/sec: 78.39 - lr: 0.000781\n",
            "2022-06-17 11:09:44,532 epoch 43 - iter 92/469 - loss 0.00058263 - samples/sec: 75.60 - lr: 0.000781\n",
            "2022-06-17 11:10:03,575 epoch 43 - iter 138/469 - loss 0.00063457 - samples/sec: 77.33 - lr: 0.000781\n",
            "2022-06-17 11:10:21,720 epoch 43 - iter 184/469 - loss 0.00078850 - samples/sec: 81.16 - lr: 0.000781\n",
            "2022-06-17 11:10:40,348 epoch 43 - iter 230/469 - loss 0.00080705 - samples/sec: 79.06 - lr: 0.000781\n",
            "2022-06-17 11:10:59,260 epoch 43 - iter 276/469 - loss 0.00091158 - samples/sec: 77.87 - lr: 0.000781\n",
            "2022-06-17 11:11:17,703 epoch 43 - iter 322/469 - loss 0.00092820 - samples/sec: 79.85 - lr: 0.000781\n",
            "2022-06-17 11:11:36,758 epoch 43 - iter 368/469 - loss 0.00089950 - samples/sec: 77.28 - lr: 0.000781\n",
            "2022-06-17 11:11:55,515 epoch 43 - iter 414/469 - loss 0.00093835 - samples/sec: 78.51 - lr: 0.000781\n",
            "2022-06-17 11:12:14,445 epoch 43 - iter 460/469 - loss 0.00092988 - samples/sec: 77.79 - lr: 0.000781\n",
            "2022-06-17 11:12:17,952 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:12:17,954 EPOCH 43 done: loss 0.0009 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:12:40,917 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:12:40,972 DEV : loss 0.16627006232738495 - f1-score (micro avg)  0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:12:41,438 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 11:12:41,441 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:13:01,593 epoch 44 - iter 46/469 - loss 0.00081600 - samples/sec: 73.08 - lr: 0.000781\n",
            "2022-06-17 11:13:20,723 epoch 44 - iter 92/469 - loss 0.00071849 - samples/sec: 76.98 - lr: 0.000781\n",
            "2022-06-17 11:13:39,192 epoch 44 - iter 138/469 - loss 0.00106834 - samples/sec: 79.74 - lr: 0.000781\n",
            "2022-06-17 11:13:57,832 epoch 44 - iter 184/469 - loss 0.00093983 - samples/sec: 79.00 - lr: 0.000781\n",
            "2022-06-17 11:14:17,042 epoch 44 - iter 230/469 - loss 0.00101120 - samples/sec: 76.66 - lr: 0.000781\n",
            "2022-06-17 11:14:35,284 epoch 44 - iter 276/469 - loss 0.00091253 - samples/sec: 80.73 - lr: 0.000781\n",
            "2022-06-17 11:14:53,992 epoch 44 - iter 322/469 - loss 0.00108537 - samples/sec: 78.72 - lr: 0.000781\n",
            "2022-06-17 11:15:12,547 epoch 44 - iter 368/469 - loss 0.00115257 - samples/sec: 79.37 - lr: 0.000781\n",
            "2022-06-17 11:15:31,455 epoch 44 - iter 414/469 - loss 0.00121149 - samples/sec: 77.88 - lr: 0.000781\n",
            "2022-06-17 11:15:50,415 epoch 44 - iter 460/469 - loss 0.00115294 - samples/sec: 77.68 - lr: 0.000781\n",
            "2022-06-17 11:15:53,856 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:15:53,858 EPOCH 44 done: loss 0.0011 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:22<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:16:16,798 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:16:16,854 DEV : loss 0.16715288162231445 - f1-score (micro avg)  0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:16:17,317 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 11:16:17,320 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:16:35,559 epoch 45 - iter 46/469 - loss 0.00052835 - samples/sec: 80.75 - lr: 0.000781\n",
            "2022-06-17 11:16:54,774 epoch 45 - iter 92/469 - loss 0.00197521 - samples/sec: 76.64 - lr: 0.000781\n",
            "2022-06-17 11:17:13,830 epoch 45 - iter 138/469 - loss 0.00170437 - samples/sec: 77.28 - lr: 0.000781\n",
            "2022-06-17 11:17:32,463 epoch 45 - iter 184/469 - loss 0.00146491 - samples/sec: 79.03 - lr: 0.000781\n",
            "2022-06-17 11:17:51,415 epoch 45 - iter 230/469 - loss 0.00125649 - samples/sec: 77.70 - lr: 0.000781\n",
            "2022-06-17 11:18:10,650 epoch 45 - iter 276/469 - loss 0.00127797 - samples/sec: 76.56 - lr: 0.000781\n",
            "2022-06-17 11:18:29,944 epoch 45 - iter 322/469 - loss 0.00112980 - samples/sec: 76.32 - lr: 0.000781\n",
            "2022-06-17 11:18:48,174 epoch 45 - iter 368/469 - loss 0.00107164 - samples/sec: 80.78 - lr: 0.000781\n",
            "2022-06-17 11:19:06,288 epoch 45 - iter 414/469 - loss 0.00099335 - samples/sec: 81.30 - lr: 0.000781\n",
            "2022-06-17 11:19:25,293 epoch 45 - iter 460/469 - loss 0.00092512 - samples/sec: 77.49 - lr: 0.000781\n",
            "2022-06-17 11:19:28,696 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:19:28,698 EPOCH 45 done: loss 0.0009 - lr 0.000781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:19:53,048 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:19:53,104 DEV : loss 0.16766488552093506 - f1-score (micro avg)  0.9436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:19:53,574 Epoch    45: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-06-17 11:19:53,577 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 11:19:53,580 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:20:11,897 epoch 46 - iter 46/469 - loss 0.00136182 - samples/sec: 80.41 - lr: 0.000391\n",
            "2022-06-17 11:20:30,202 epoch 46 - iter 92/469 - loss 0.00089828 - samples/sec: 80.46 - lr: 0.000391\n",
            "2022-06-17 11:20:48,323 epoch 46 - iter 138/469 - loss 0.00084517 - samples/sec: 81.27 - lr: 0.000391\n",
            "2022-06-17 11:21:06,738 epoch 46 - iter 184/469 - loss 0.00080328 - samples/sec: 79.97 - lr: 0.000391\n",
            "2022-06-17 11:21:25,846 epoch 46 - iter 230/469 - loss 0.00082539 - samples/sec: 77.07 - lr: 0.000391\n",
            "2022-06-17 11:21:45,220 epoch 46 - iter 276/469 - loss 0.00083329 - samples/sec: 76.01 - lr: 0.000391\n",
            "2022-06-17 11:22:04,232 epoch 46 - iter 322/469 - loss 0.00073412 - samples/sec: 77.46 - lr: 0.000391\n",
            "2022-06-17 11:22:23,385 epoch 46 - iter 368/469 - loss 0.00065493 - samples/sec: 76.88 - lr: 0.000391\n",
            "2022-06-17 11:22:42,736 epoch 46 - iter 414/469 - loss 0.00074236 - samples/sec: 76.10 - lr: 0.000391\n",
            "2022-06-17 11:23:01,920 epoch 46 - iter 460/469 - loss 0.00080274 - samples/sec: 76.76 - lr: 0.000391\n",
            "2022-06-17 11:23:05,192 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:23:05,194 EPOCH 46 done: loss 0.0008 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:23:29,562 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:23:29,622 DEV : loss 0.16762720048427582 - f1-score (micro avg)  0.9436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:23:30,093 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 11:23:30,096 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:23:49,029 epoch 47 - iter 46/469 - loss 0.00083611 - samples/sec: 77.79 - lr: 0.000391\n",
            "2022-06-17 11:24:07,736 epoch 47 - iter 92/469 - loss 0.00103456 - samples/sec: 78.72 - lr: 0.000391\n",
            "2022-06-17 11:24:26,707 epoch 47 - iter 138/469 - loss 0.00089792 - samples/sec: 77.63 - lr: 0.000391\n",
            "2022-06-17 11:24:45,976 epoch 47 - iter 184/469 - loss 0.00089197 - samples/sec: 76.43 - lr: 0.000391\n",
            "2022-06-17 11:25:04,817 epoch 47 - iter 230/469 - loss 0.00090855 - samples/sec: 78.16 - lr: 0.000391\n",
            "2022-06-17 11:25:23,714 epoch 47 - iter 276/469 - loss 0.00105793 - samples/sec: 77.93 - lr: 0.000391\n",
            "2022-06-17 11:25:42,463 epoch 47 - iter 322/469 - loss 0.00106298 - samples/sec: 78.54 - lr: 0.000391\n",
            "2022-06-17 11:26:00,987 epoch 47 - iter 368/469 - loss 0.00109006 - samples/sec: 79.50 - lr: 0.000391\n",
            "2022-06-17 11:26:19,521 epoch 47 - iter 414/469 - loss 0.00107369 - samples/sec: 79.46 - lr: 0.000391\n",
            "2022-06-17 11:26:37,857 epoch 47 - iter 460/469 - loss 0.00110688 - samples/sec: 80.31 - lr: 0.000391\n",
            "2022-06-17 11:26:41,214 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:26:41,216 EPOCH 47 done: loss 0.0011 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:27:05,622 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:27:05,679 DEV : loss 0.1675945520401001 - f1-score (micro avg)  0.9436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:27:06,143 BAD EPOCHS (no improvement): 2\n",
            "2022-06-17 11:27:06,147 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:27:25,647 epoch 48 - iter 46/469 - loss 0.00013223 - samples/sec: 75.52 - lr: 0.000391\n",
            "2022-06-17 11:27:44,336 epoch 48 - iter 92/469 - loss 0.00086728 - samples/sec: 78.80 - lr: 0.000391\n",
            "2022-06-17 11:28:02,590 epoch 48 - iter 138/469 - loss 0.00123083 - samples/sec: 80.68 - lr: 0.000391\n",
            "2022-06-17 11:28:21,656 epoch 48 - iter 184/469 - loss 0.00128384 - samples/sec: 77.24 - lr: 0.000391\n",
            "2022-06-17 11:28:40,437 epoch 48 - iter 230/469 - loss 0.00124300 - samples/sec: 78.41 - lr: 0.000391\n",
            "2022-06-17 11:28:59,379 epoch 48 - iter 276/469 - loss 0.00107155 - samples/sec: 77.74 - lr: 0.000391\n",
            "2022-06-17 11:29:18,560 epoch 48 - iter 322/469 - loss 0.00113538 - samples/sec: 76.77 - lr: 0.000391\n",
            "2022-06-17 11:29:37,382 epoch 48 - iter 368/469 - loss 0.00106434 - samples/sec: 78.24 - lr: 0.000391\n",
            "2022-06-17 11:29:56,647 epoch 48 - iter 414/469 - loss 0.00105089 - samples/sec: 76.44 - lr: 0.000391\n",
            "2022-06-17 11:30:14,705 epoch 48 - iter 460/469 - loss 0.00097349 - samples/sec: 81.55 - lr: 0.000391\n",
            "2022-06-17 11:30:18,217 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:30:18,219 EPOCH 48 done: loss 0.0010 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:23<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:30:41,293 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:30:41,349 DEV : loss 0.16765789687633514 - f1-score (micro avg)  0.9434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:30:41,815 BAD EPOCHS (no improvement): 3\n",
            "2022-06-17 11:30:41,819 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:31:01,184 epoch 49 - iter 46/469 - loss 0.00092113 - samples/sec: 76.06 - lr: 0.000391\n",
            "2022-06-17 11:31:20,319 epoch 49 - iter 92/469 - loss 0.00109016 - samples/sec: 76.96 - lr: 0.000391\n",
            "2022-06-17 11:31:39,013 epoch 49 - iter 138/469 - loss 0.00130992 - samples/sec: 78.78 - lr: 0.000391\n",
            "2022-06-17 11:31:57,781 epoch 49 - iter 184/469 - loss 0.00118542 - samples/sec: 78.46 - lr: 0.000391\n",
            "2022-06-17 11:32:16,463 epoch 49 - iter 230/469 - loss 0.00126016 - samples/sec: 78.83 - lr: 0.000391\n",
            "2022-06-17 11:32:34,934 epoch 49 - iter 276/469 - loss 0.00139020 - samples/sec: 79.73 - lr: 0.000391\n",
            "2022-06-17 11:32:53,925 epoch 49 - iter 322/469 - loss 0.00131047 - samples/sec: 77.54 - lr: 0.000391\n",
            "2022-06-17 11:33:12,390 epoch 49 - iter 368/469 - loss 0.00125158 - samples/sec: 79.75 - lr: 0.000391\n",
            "2022-06-17 11:33:31,093 epoch 49 - iter 414/469 - loss 0.00112190 - samples/sec: 78.74 - lr: 0.000391\n",
            "2022-06-17 11:33:49,996 epoch 49 - iter 460/469 - loss 0.00106498 - samples/sec: 77.90 - lr: 0.000391\n",
            "2022-06-17 11:33:53,469 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:33:53,471 EPOCH 49 done: loss 0.0010 - lr 0.000391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:34:17,834 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:34:17,892 DEV : loss 0.16750769317150116 - f1-score (micro avg)  0.9438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:34:18,356 Epoch    49: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-06-17 11:34:18,358 BAD EPOCHS (no improvement): 4\n",
            "2022-06-17 11:34:18,363 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:34:37,380 epoch 50 - iter 46/469 - loss 0.00004841 - samples/sec: 77.45 - lr: 0.000195\n",
            "2022-06-17 11:34:56,370 epoch 50 - iter 92/469 - loss 0.00041524 - samples/sec: 77.55 - lr: 0.000195\n",
            "2022-06-17 11:35:14,975 epoch 50 - iter 138/469 - loss 0.00061655 - samples/sec: 79.16 - lr: 0.000195\n",
            "2022-06-17 11:35:33,689 epoch 50 - iter 184/469 - loss 0.00053863 - samples/sec: 78.69 - lr: 0.000195\n",
            "2022-06-17 11:35:52,518 epoch 50 - iter 230/469 - loss 0.00063807 - samples/sec: 78.21 - lr: 0.000195\n",
            "2022-06-17 11:36:11,609 epoch 50 - iter 276/469 - loss 0.00068141 - samples/sec: 77.14 - lr: 0.000195\n",
            "2022-06-17 11:36:30,321 epoch 50 - iter 322/469 - loss 0.00071549 - samples/sec: 78.70 - lr: 0.000195\n",
            "2022-06-17 11:36:48,557 epoch 50 - iter 368/469 - loss 0.00067224 - samples/sec: 80.75 - lr: 0.000195\n",
            "2022-06-17 11:37:07,502 epoch 50 - iter 414/469 - loss 0.00061342 - samples/sec: 77.73 - lr: 0.000195\n",
            "2022-06-17 11:37:26,403 epoch 50 - iter 460/469 - loss 0.00068439 - samples/sec: 77.92 - lr: 0.000195\n",
            "2022-06-17 11:37:29,743 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:37:29,746 EPOCH 50 done: loss 0.0007 - lr 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:37:54,199 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:37:54,259 DEV : loss 0.16759750247001648 - f1-score (micro avg)  0.9438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:37:54,728 BAD EPOCHS (no improvement): 1\n",
            "2022-06-17 11:37:57,015 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-17 11:37:57,019 loading file /content/model/conllpp/best-model.pt\n",
            "2022-06-17 11:38:00,649 SequenceTagger predicts: Dictionary with 17 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 116/116 [00:26<00:00,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 11:38:27,796 Evaluating as a multi-label problem: False\n",
            "2022-06-17 11:38:27,851 0.9167\t0.9149\t0.9158\t0.8764\n",
            "2022-06-17 11:38:27,853 \n",
            "Results:\n",
            "- F-score (micro) 0.9158\n",
            "- F-score (macro) 0.9026\n",
            "- Accuracy 0.8764\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG     0.8954    0.8682    0.8816      1715\n",
            "         LOC     0.9296    0.9544    0.9418      1646\n",
            "         PER     0.9726    0.9654    0.9690      1618\n",
            "        MISC     0.8128    0.8230    0.8179       723\n",
            "\n",
            "   micro avg     0.9167    0.9149    0.9158      5702\n",
            "   macro avg     0.9026    0.9028    0.9026      5702\n",
            "weighted avg     0.9167    0.9149    0.9157      5702\n",
            "\n",
            "2022-06-17 11:38:27,854 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.11812306940555573,\n",
              "  0.06859636306762695,\n",
              "  0.06514368206262589,\n",
              "  0.05592651292681694,\n",
              "  0.06525728851556778,\n",
              "  0.0605003647506237,\n",
              "  0.07066928595304489,\n",
              "  0.061316538602113724,\n",
              "  0.06465733796358109,\n",
              "  0.08457881957292557,\n",
              "  0.06976239383220673,\n",
              "  0.09573764353990555,\n",
              "  0.08056985586881638,\n",
              "  0.10226253420114517,\n",
              "  0.10129936039447784,\n",
              "  0.10863196849822998,\n",
              "  0.09911255538463593,\n",
              "  0.12595795094966888,\n",
              "  0.12453508377075195,\n",
              "  0.125911146402359,\n",
              "  0.1391693353652954,\n",
              "  0.1427735984325409,\n",
              "  0.1388322114944458,\n",
              "  0.14742818474769592,\n",
              "  0.15061542391777039,\n",
              "  0.1478821039199829,\n",
              "  0.15215998888015747,\n",
              "  0.1583978235721588,\n",
              "  0.15556968748569489,\n",
              "  0.16040655970573425,\n",
              "  0.1576801836490631,\n",
              "  0.1598232239484787,\n",
              "  0.16121862828731537,\n",
              "  0.16081681847572327,\n",
              "  0.16388776898384094,\n",
              "  0.16377849876880646,\n",
              "  0.16497555375099182,\n",
              "  0.16435116529464722,\n",
              "  0.1650353968143463,\n",
              "  0.16567803919315338,\n",
              "  0.16575579345226288,\n",
              "  0.1660126894712448,\n",
              "  0.16627006232738495,\n",
              "  0.16715288162231445,\n",
              "  0.16766488552093506,\n",
              "  0.16762720048427582,\n",
              "  0.1675945520401001,\n",
              "  0.16765789687633514,\n",
              "  0.16750769317150116,\n",
              "  0.16759750247001648],\n",
              " 'dev_score_history': [0.8690122933446376,\n",
              "  0.908407153601872,\n",
              "  0.9112605042016806,\n",
              "  0.9318560479840053,\n",
              "  0.9308260577568838,\n",
              "  0.9372167198254154,\n",
              "  0.9315554055194532,\n",
              "  0.9409987410826689,\n",
              "  0.9428595472523774,\n",
              "  0.9229487713452728,\n",
              "  0.9342845153168275,\n",
              "  0.926570779712339,\n",
              "  0.934853693300914,\n",
              "  0.9362311515457838,\n",
              "  0.9450549450549451,\n",
              "  0.9443651925820258,\n",
              "  0.9461480299084264,\n",
              "  0.9405132519983173,\n",
              "  0.9377829951366762,\n",
              "  0.9404741886665546,\n",
              "  0.9392794154698917,\n",
              "  0.9450937526275962,\n",
              "  0.9429459709268129,\n",
              "  0.9395465994962217,\n",
              "  0.9423335574983188,\n",
              "  0.94291719209752,\n",
              "  0.9422558922558923,\n",
              "  0.943256440478195,\n",
              "  0.9452711223203025,\n",
              "  0.9443836769036601,\n",
              "  0.9460916442048517,\n",
              "  0.9455862533692723,\n",
              "  0.9458708645508882,\n",
              "  0.9452342895600236,\n",
              "  0.9448513934495243,\n",
              "  0.9448513934495243,\n",
              "  0.9448235195013057,\n",
              "  0.9437805083319307,\n",
              "  0.9437105595288179,\n",
              "  0.9441171519946137,\n",
              "  0.9438693932508626,\n",
              "  0.9437805083319307,\n",
              "  0.9437010855844483,\n",
              "  0.9437010855844483,\n",
              "  0.9436026936026937,\n",
              "  0.9436121865005891,\n",
              "  0.9436121865005891,\n",
              "  0.9434438646692476,\n",
              "  0.9437805083319307,\n",
              "  0.9437805083319307],\n",
              " 'test_score': 0.9158255068901957,\n",
              " 'train_loss_history': [0.2824703964641186,\n",
              "  0.09732349622386373,\n",
              "  0.06707023250878177,\n",
              "  0.05334318245176987,\n",
              "  0.04288817972743599,\n",
              "  0.03544695225126618,\n",
              "  0.030019717545809496,\n",
              "  0.026801662172561844,\n",
              "  0.02447259222092529,\n",
              "  0.02379597861600606,\n",
              "  0.021433011910118736,\n",
              "  0.020238205412540247,\n",
              "  0.01913511708295096,\n",
              "  0.01018552991047374,\n",
              "  0.007785464402906831,\n",
              "  0.007627408779571767,\n",
              "  0.006551869968595342,\n",
              "  0.006216051583816373,\n",
              "  0.005056275428924418,\n",
              "  0.005548392854978825,\n",
              "  0.004684254479918527,\n",
              "  0.003090752183325577,\n",
              "  0.002351397905040242,\n",
              "  0.002185460692719429,\n",
              "  0.0022748316941405256,\n",
              "  0.001662409683296942,\n",
              "  0.0014066918698777784,\n",
              "  0.0012418866943555964,\n",
              "  0.0012377712937931232,\n",
              "  0.001055470495317266,\n",
              "  0.001126431275484839,\n",
              "  0.0011020053852485209,\n",
              "  0.0010682644293833993,\n",
              "  0.0009466498658503036,\n",
              "  0.0008690679746535413,\n",
              "  0.001217527418038919,\n",
              "  0.0008995367982023337,\n",
              "  0.0009289408847586241,\n",
              "  0.000929811223419402,\n",
              "  0.0009491729910935273,\n",
              "  0.0008171578327840733,\n",
              "  0.0011758402664459042,\n",
              "  0.0009185764904193349,\n",
              "  0.0011351636196319282,\n",
              "  0.0009200539698491512,\n",
              "  0.000798083481873631,\n",
              "  0.0010886961360717477,\n",
              "  0.00095650868437921,\n",
              "  0.0010461138924949369,\n",
              "  0.0006744150791177491]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX1abswOTdfl"
      },
      "source": [
        "We see that the output accuracy (F1-score) for our new model is **93.5%** (F1-score (micro) 0.9354)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbaB4a27Tq7P"
      },
      "source": [
        "## Using the Model (Running Inference)\n",
        "\n",
        "Running the model to do some predictions/inference is as simple as calling `tagger.predict(sentence)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOtVbbI1Jsdz",
        "outputId": "fd326e37-a5fa-4322-e474-e1ed0bc9fe96"
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "input_sentence = [\n",
        "                  'George Washington went to Washington to study in University of Washington.',\n",
        "                  'Kobe Bryant is top 10 players in NBA history.',\n",
        "                  'Stephen Curry has 4 NBA titles.',\n",
        "                  'President Bush is hiding in bushes in Irap.',\n",
        "                  'Steve Jobs is find a job.'\n",
        "                  ]\n",
        "tagger: SequenceTagger = SequenceTagger.load(\"/content/model/conllpp/final-model.pt\")\n",
        "\n",
        "for sentence in input_sentence:    \n",
        "    sentence_each: Sentence = Sentence(sentence)\n",
        "    tagger.predict(sentence_each)\n",
        "    print(sentence_each.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-17 08:20:27,984 loading file /content/model/conllpp/final-model.pt\n",
            "2022-06-17 08:20:28,716 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>\n",
            "Sentence: \"George Washington went to Washington to study in University of Washington .\" → [\"George Washington\"/PER, \"Washington\"/LOC, \"University\"/LOC, \"Washington\"/LOC]\n",
            "Sentence: \"Kobe Bryant is top 10 players in NBA history .\" → [\"Kobe Bryant\"/PER]\n",
            "Sentence: \"Stephen Curry has 4 NBA titles .\" → [\"Stephen Curry\"/PER]\n",
            "Sentence: \"President Bush is hiding in bushes in Irap .\" → [\"Bush\"/LOC, \"Irap\"/LOC]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh9_zd6aUqMG"
      },
      "source": [
        "Move the model files from our local directory to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P7UpDkVUyQQ"
      },
      "source": [
        "shutil.move('/content/model/conllpp/', \"/content/drive/My Drive/model/\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}